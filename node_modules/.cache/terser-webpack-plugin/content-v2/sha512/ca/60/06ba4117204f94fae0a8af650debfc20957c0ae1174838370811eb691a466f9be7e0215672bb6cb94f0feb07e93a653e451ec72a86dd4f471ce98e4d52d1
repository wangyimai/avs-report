{"code":"(function(e){function t(t){for(var b,i,n=t[0],s=t[1],j=t[2],f=0,l=[];f<n.length;f++)i=n[f],Object.prototype.hasOwnProperty.call(a,i)&&a[i]&&l.push(a[i][0]),a[i]=0;for(b in s)Object.prototype.hasOwnProperty.call(s,b)&&(e[b]=s[b]);O&&O(t);while(l.length)l.shift()();return r.push.apply(r,j||[]),c()}function c(){for(var e,t=0;t<r.length;t++){for(var c=r[t],b=!0,n=1;n<c.length;n++){var s=c[n];0!==a[s]&&(b=!1)}b&&(r.splice(t--,1),e=i(i.s=c[0]))}return e}var b={},a={app:0},r=[];function i(t){if(b[t])return b[t].exports;var c=b[t]={i:t,l:!1,exports:{}};return e[t].call(c.exports,c,c.exports,i),c.l=!0,c.exports}i.m=e,i.c=b,i.d=function(e,t,c){i.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:c})},i.r=function(e){\"undefined\"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},i.t=function(e,t){if(1&t&&(e=i(e)),8&t)return e;if(4&t&&\"object\"===typeof e&&e&&e.__esModule)return e;var c=Object.create(null);if(i.r(c),Object.defineProperty(c,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var b in e)i.d(c,b,function(t){return e[t]}.bind(null,b));return c},i.n=function(e){var t=e&&e.__esModule?function(){return e[\"default\"]}:function(){return e};return i.d(t,\"a\",t),t},i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},i.p=\"/\";var n=window[\"webpackJsonp\"]=window[\"webpackJsonp\"]||[],s=n.push.bind(n);n.push=t,n=n.slice();for(var j=0;j<n.length;j++)t(n[j]);var O=s;r.push([0,\"chunk-vendors\"]),c()})({0:function(e,t,c){e.exports=c(\"56d76\")},\"022f\":function(e,t,c){\"use strict\";c(\"e0c3\")},\"0691\":function(e,t,c){e.exports=c.p+\"img/dlclshxwsfbj.e883b0f7.png\"},\"0928\":function(e,t,c){},\"1ac8\":function(e,t,c){},\"1b12\":function(e,t,c){e.exports=c.p+\"img/mbjc.d2b39a07.webp\"},\"1c40\":function(e,t,c){e.exports=c.p+\"img/zdjsjsgjt.20d666f2.png\"},\"1d6f\":function(e,t,c){e.exports=c.p+\"img/dlclkzlc.e0b142e0.png\"},\"1ffb\":function(e,t,c){\"use strict\";c(\"9e80\")},\"2afe\":function(e,t,c){e.exports=c.p+\"img/xyzswjjddb.483f7c54.png\"},\"2e78\":function(e,t,c){\"use strict\";c(\"e2c5\")},\"2fd8\":function(e,t,c){\"use strict\";c(\"8e88\")},\"30cd\":function(e,t,c){},\"33ba\":function(e,t,c){e.exports=c.p+\"img/zdjsmnq.4e07078d.png\"},3450:function(e,t,c){e.exports=c.p+\"img/dlzdcjljffbj.6fcb4595.png\"},\"38c0\":function(e,t,c){e.exports=c.p+\"img/xdzdjsjslc.964d2e6c.png\"},4236:function(e,t,c){},\"494d\":function(e,t,c){\"use strict\";c(\"645d\")},\"4a2b\":function(e,t,c){e.exports=c.p+\"img/dlydghff.13c211f1.png\"},\"4b59\":function(e,t,c){e.exports=c.p+\"img/dlkzsfbj.c16da1dc.png\"},\"4c72\":function(e,t,c){\"use strict\";c(\"4236\")},\"56d7\":function(e,t,c){},\"56d76\":function(e,t,c){\"use strict\";c.r(t);c(\"e260\"),c(\"e6cf\"),c(\"cca6\"),c(\"a79d\");var b=c(\"7a23\"),a={class:\"container\"},r={id:\"columns\",class:\"columns is-desktop\"};function i(e,t,c,i,n,s){var j=Object(b[\"v\"])(\"Header\"),O=Object(b[\"v\"])(\"begining\"),f=Object(b[\"v\"])(\"foreword-section\"),l=Object(b[\"v\"])(\"trade-section\"),o=Object(b[\"v\"])(\"sensor-section\"),d=Object(b[\"v\"])(\"DL-section\"),u=Object(b[\"v\"])(\"RL-section\"),h=Object(b[\"v\"])(\"question-section\"),v=Object(b[\"v\"])(\"end\"),p=Object(b[\"v\"])(\"sections\"),m=Object(b[\"v\"])(\"table-of-contents\"),g=Object(b[\"v\"])(\"Footer\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[Object(b[\"i\"])(j),Object(b[\"f\"])(\"div\",a,[Object(b[\"f\"])(\"div\",r,[Object(b[\"i\"])(p,{class:\"column is-9-desktop\"},{default:Object(b[\"B\"])((function(){return[Object(b[\"i\"])(O),Object(b[\"i\"])(f),Object(b[\"i\"])(l),Object(b[\"i\"])(o),Object(b[\"i\"])(d),Object(b[\"i\"])(u),Object(b[\"i\"])(h),Object(b[\"i\"])(v)]})),_:1}),Object(b[\"i\"])(m,{class:\"column is-3\"})])]),Object(b[\"i\"])(g)],64)}var n={id:\"header\",class:\"hero is-fullheight\"},s=Object(b[\"g\"])('<div class=\"hero-head\"><nav class=\"navbar\"><div class=\"container\"><div class=\"navbar-start\"><a id=\"github-link\" href=\"https://www.baidu.com/\" class=\"animate__animated animate__rollIn navbar-item\"><svg height=\"20\" aria-hidden=\"true\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"20\" data-view-component=\"true\" style=\"display:inline;color:white;\"><path fill-rule=\"evenodd\" fill=\"#ffffff\" d=\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z\"></path></svg><span style=\"margin-left:0.3em;\">GitHub</span></a><a id=\"bilibili-link\" href=\"https://www.baidu.com/\" class=\"animate__animated animate__rollIn navbar-item\"><svg viewBox=\"-.64 -4.64 2187.5 1004.88\" width=\"70\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m2030.61 892.82c-9.77 0-18.55 0-26.37-.98-16.6-.97-33.2-1.95-49.8-1.95-10.74 0-10.74 0-11.72-10.74l-15.63-177.74-15.62-147.46-10.74-90.82-9.77-79.1-17.58-123.05c-5.86-43.94-12.69-86.91-21.48-130.86-.98-6.83-.98-7.81 6.84-8.79 30.27-5.86 61.52-8.79 92.77-8.79h10.74c4.88.98 7.81 3.91 8.79 9.77l3.91 67.38 27.34 364.26 13.67 166.99 8.79 95.71zm-1197.27-780.28h17.58c8.79 0 10.74 2.93 10.74 11.72l7.82 118.17 17.58 245.11 10.74 127.93 7.81 98.64 15.63 169.92c0 7.81-.98 8.79-8.79 8.79l-70.32-2.93c-4.88.98-7.81-1.95-7.81-6.84l-2.93-34.18c-2.93-29.29-5.86-58.59-7.81-88.86l-15.63-154.3-16.6-139.65-11.72-98.63-12.69-89.85c-5.86-40.04-12.7-81.05-19.53-121.09l-4.89-27.34c-.97-4.89 0-6.84 4.89-7.82 27.34-4.88 53.71-9.76 85.93-8.79zm982.43 393.56c24.41 0 27.34.98 31.25 24.41 4.88 29.3 8.79 58.6 11.72 87.89l10.74 94.73 20.51 201.17c.97 4.89 0 6.84-4.89 6.84l-76.17 8.79c-7.81.97-9.77 0-10.74-7.81l-43.95-224.61-27.34-149.42-3.91-20.51c-.97-3.9.98-6.83 4.89-7.81 30.27-6.83 59.57-11.72 87.89-13.67zm-1110.36 0c26.37-.98 29.3 1.95 32.23 26.37 6.84 40.04 11.72 79.1 15.63 119.14l12.69 117.18 7.81 79.11 6.84 63.47c0 8.79-.98 10.75-8.79 11.72l-72.26 6.84c-7.82.97-9.77 0-10.75-7.81l-59.57-306.65-15.62-86.91c-.98-4.88.97-7.81 5.86-8.79 30.27-6.83 58.59-11.72 85.93-13.67zm373.05 302.73v125c.98 5.86-1.95 8.79-7.81 7.82h-23.44c-16.6 0-33.2.97-49.8 1.95-8.79.98-9.77.98-10.75-9.77l-15.62-175.78-7.81-86.91-11.72-132.81c-.98-10.75.98-12.7 9.76-13.68 27.35-2.93 54.69-2.93 82.04-1.95l20.5 2.93c7.82 2.93 8.79 3.91 8.79 11.72l2.93 52.73.98 58.6c.98 53.71 1.95 106.44 1.95 160.15zm1108.4 5.86v120.12c0 4.88-1.95 7.81-6.84 6.84h-35.15c-13.67 0-27.35.97-40.04 1.95-7.81.98-8.79 0-9.77-8.79l-20.5-228.52-10.75-113.28-3.9-57.61c-.98-7.82.97-9.77 8.79-9.77 32.22-3.91 65.43-4.88 97.65-.98 12.7.98 14.65 4.89 15.63 17.58l2.93 129.88zm-399.41-516.6c9.76 0 18.55.98 25.39 1.95 4.88.98 6.83 2.93 7.81 7.82l12.69 135.74c2.93 11.72.98 13.67-10.74 13.67l-33.2 1.95c-6.84.98-9.77 1.96-9.77-8.78l-13.67-110.36-3.9-31.25c-.98-5.86.97-8.79 6.83-9.76zm-1106.45 0c7.81 0 15.63.98 22.46 1.95 3.91.98 5.86 2.93 6.84 7.82l3.9 34.18 9.77 106.44c.98 7.81.98 8.79-6.84 8.79l-38.08 1.95c-7.81.98-8.79 0-9.77-7.81l-8.79-78.12-7.81-65.43c-.98-4.89.98-7.82 5.86-7.82 6.84-.97 14.65-1.95 22.46-1.95zm389.65 97.66v67.38c.98 10.74-.98 10.74-9.77 10.74-12.69 0-24.41-.97-36.13-1.95-7.81-.98-8.79-.98-7.81-8.79l-2.93-83.01c0-18.55 0-37.11-.98-55.66-.97-8.79 0-9.77 8.79-9.77 13.67 0 27.34.98 41.02 2.93 7.81 0 7.81 1.96 7.81 9.77zm1109.37.97v67.39c0 8.79-.97 9.76-9.76 9.76l-37.11-1.95c-5.86-.98-8.79-3.91-7.81-8.79l-2.93-139.65c0-7.81.97-8.79 8.79-8.79 12.69 0 24.41.98 36.13 1.96 14.65.97 12.69 3.9 12.69 14.64zm-1529.29 52.74c.97 11.72 0 13.67-11.72 14.65l-23.44 5.86c-7.81 2.93-8.79.97-9.76-5.86l-24.42-137.7c-2.93-8.79-.98-10.74 7.81-11.72l34.18-5.86c7.82-.97 9.77-.97 9.77 6.84 2.93 16.6 5.86 33.2 7.81 49.8l9.77 78.13zm1039.06-133.79c14.65-2.93 30.27-4.88 45.9-6.84 4.88-.97 6.83 1.96 7.81 6.84l7.81 53.71c3.91 26.37 6.84 52.73 7.82 79.1v7.81c.97 3.91-.98 6.84-4.89 7.82l-31.25 6.83c-4.88.98-6.83-.97-7.81-5.86l-25.39-145.5zm-693.36 105.47c0 15.62-.98 30.27-1.95 43.94 0 4.89-1.96 6.84-6.84 7.82l-30.27 2.93c-4.88.97-6.84-1.96-6.84-6.84-1.95-14.65-2.93-28.32-3.9-42.97-1.96-26.37-3.91-53.71-4.89-81.05l-1.95-19.53c-.98-3.91.98-5.86 4.88-5.86l40.04-2.93c6.84 0 8.79.97 8.79 8.79zm1107.42-15.63c.98 18.56.98 38.09 0 56.64.98 8.79-.97 10.75-9.76 10.75l-27.35 2.93c-4.88.97-7.81-1.96-7.81-6.84-.98-24.41-2.93-49.8-4.88-74.22l-3.91-68.36c-.98-4.88.98-6.83 4.88-6.83l39.07-2.93c6.83 0 7.81.97 7.81 8.79 1.95 26.36 2.93 53.71 1.95 80.07zm-1491.21 333.01c15.63 18.56 18.56 39.06 11.72 61.52-5.86 21.49-16.6 40.04-32.23 55.67-25.39 26.37-54.68 47.85-86.91 64.45-55.66 29.3-113.28 49.81-174.81 60.55-43.94 8.79-87.89 14.65-131.83 17.58-13.67.97-27.34.97-41.02.97h-29.29c-7.82 0-9.77-1.95-10.75-9.76l-6.83-94.73-18.56-186.52-20.5-177.74-11.72-94.72-12.7-90.82c-6.83-49.81-15.62-99.61-24.41-149.42-6.84-40.04-13.67-80.08-22.46-120.11-.98-4.89 0-8.79 4.88-9.77l135.74-56.64c8.79-3.91 16.6-6.84 25.39-8.79 5.86-.98 8.79.98 7.81 6.84 0 15.62 0 31.25-.97 47.85l-.98 12.69c-.97 56.64-.97 113.28 0 170.9.98 49.81 3.91 100.59 6.84 150.39 4.88 78.13 12.69 156.25 20.51 233.4 0 7.81.97 7.81 9.76 6.84 16.6-2.93 32.23-3.91 48.83-3.91 51.76 0 103.51 5.86 153.32 18.55 43.94 10.75 85.94 25.4 127.93 43.95 20.51 9.77 39.06 21.48 56.64 35.16 6.84 4.88 11.72 9.76 16.6 15.62zm1100.59-8.79c20.51 16.6 27.34 39.06 21.48 65.43-4.88 21.49-14.65 40.04-29.3 56.64-23.43 26.37-50.78 46.88-81.05 63.48-58.59 32.23-121.09 54.69-187.5 66.41-36.13 6.83-72.27 12.69-108.4 15.62-20.51 1.95-42.97 2.93-65.43 1.95h-26.37c-5.85.98-8.78-1.95-8.78-7.81-1.96-27.34-3.91-54.69-6.84-82.03l-15.63-166.99-16.6-145.51-20.5-164.06c-2.93-28.32-6.84-57.62-11.72-85.94l-17.58-109.38c-7.81-51.75-17.58-103.51-28.32-155.27l-.98-6.83c-1.95-4.89 0-8.79 4.88-9.77 47.86-19.53 94.73-41.02 142.58-59.57 12.7-4.88 28.32-10.74 27.35.98-3.91 36.13-2.93 72.26-3.91 107.42-.98 29.29-.98 58.59.98 86.91v22.46c0 35.16.97 70.32 3.9 104.49 1.96 45.9 4.89 92.78 8.79 138.68l8.79 98.63c.98 18.55 2.93 36.13 5.86 54.69 0 10.74 1.95 9.76 10.74 8.79 17.58-2.93 35.16-3.91 52.74-3.91 61.52.98 121.09 10.74 179.68 27.34 40.04 10.75 78.13 25.39 115.24 44.93 16.6 8.78 31.25 19.53 45.9 32.22zm-1412.11 171.88c14.65-8.79 40.04-26.37 75.19-53.71 35.16-28.32 56.64-46.88 65.43-56.64-52.73-23.44-107.42-43.95-164.06-62.5zm1247.07-105.47c2.93-2.93 1.95-4.88-.98-6.84l-23.44-9.76c-41.01-17.58-82.03-33.21-124.02-46.88l-5.86-1.95c-1.95-.98-3.9 0-6.83.98l23.43 168.94c2.93 0 4.89-.98 5.86-1.95 38.09-27.35 76.17-55.67 114.26-85.94z\" fill=\"#07a3d7\"></path></svg></a></div></div></nav></div><div class=\"hero-body\"><div class=\"container\"><p class=\"animate__animated animate__fadeInLeft title\"> 自动驾驶中的深度学习与强化学习 </p></div></div><div class=\"hero-foot\"></div>',3),j=[s];function O(e,t,c,a,r,i){return Object(b[\"p\"])(),Object(b[\"e\"])(\"section\",n,j)}var f=Object(b[\"j\"])({name:\"Header\"}),l=(c(\"6594\"),c(\"d959\")),o=c.n(l);const d=o()(f,[[\"render\",O]]);var u=d,h={class:\"footer\"},v=Object(b[\"f\"])(\"div\",{class:\"content has-text-centered\"},null,-1),p=[v];function m(e,t,c,a,r,i){return Object(b[\"p\"])(),Object(b[\"e\"])(\"footer\",h,p)}var g=Object(b[\"j\"])({name:\"Footer\"});const L=o()(g,[[\"render\",m]]);var y=L,S={id:\"sections\"};function D(e,t,c,a,r,i){return Object(b[\"p\"])(),Object(b[\"e\"])(\"div\",S,[Object(b[\"u\"])(e.$slots,\"default\",{},void 0,!0)])}var A=c(\"5c7f\"),C=Object(b[\"j\"])({name:\"Sections\",setup:function(){Object(b[\"r\"])(A[\"a\"],\"light\")}});c(\"9d82\");const N=o()(C,[[\"render\",D],[\"__scopeId\",\"data-v-f567ab7c\"]]);var V=N,x={ref:\"toc\",id:\"toc\",class:\"menu is-hidden-touch is-narrow\"},R=Object(b[\"g\"])('<br><p class=\"menu-label\"><a href=\"#intro\">摘要</a></p><p class=\"menu-label\"><a href=\"#foreword-section\">引言</a></p><ul class=\"menu-list\"><li><a href=\"#背景\">背景</a></li><li><a href=\"#国标自动驾驶等级分级\">国标自动驾驶等级分级</a></li><li><a href=\"#自动驾驶中的六大任务\">自动驾驶中的六大任务</a></li><li><a href=\"#现有综述\">现有综述的介绍</a></li><li><a href=\"#现有综述文献间的对比\">现有综述文献间的对比</a></li><li><a href=\"#本次研究的范围\">本次研究的范围</a></li></ul><p class=\"menu-label\"><a href=\"#trade-section\">行业现状</a></p><ul class=\"menu-list\"><li><a href=\"#chart-suanli\">高等级自动驾驶对芯片的算力要求</a></li><li><a href=\"#chart-marketsize\">中国智慧交通市场规模</a></li><li><a href=\"#chart-distributionrounds\">中国自动驾驶项目融资轮次</a></li></ul><p class=\"menu-label\"><a href=\"#sensor-section\">自动驾驶技术概要</a></p><ul class=\"menu-list\"><li><a href=\"#自动驾驶解决方案\">自动驾驶解决方案</a></li><li><a href=\"#自动驾驶汽车的传感器\">自动驾驶汽车的传感器</a></li><li><a href=\"#自动驾驶技术构架图\">自动驾驶技术构架图</a></li></ul><p class=\"menu-label\"><a href=\"#DL-section\">自动驾驶与深度学习</a></p><ul class=\"menu-list\"><li><a href=\"#深度场景理解\">场景理解</a></li><li><a href=\"#深度运动规划\">运动规划</a></li><li><a href=\"#深度决策\">决策</a></li><li><a href=\"#深度车辆控制\">车辆控制</a></li><li><a href=\"#深度学习车辆社会行为\">车辆社会行为</a></li><li><a href=\"#深度学习车辆通信\">车辆通信</a></li></ul><p class=\"menu-label\"><a href=\"#RL-section\">自动驾驶与强化学习</a></p><ul class=\"menu-list\"><li><a href=\"#状态空间、动作空间和奖励机制\">状态空间、动作空间和奖励机制</a></li><li><a href=\"#模拟器和场景生成工具\">模拟器和场景生成工具</a></li><li><a href=\"#强化决策\">决策</a></li><li><a href=\"#强化运动规划\">运动规划</a></li><li><a href=\"#强化车辆控制\">车辆控制</a></li><li><a href=\"#强化社会行为\">车辆社会行为</a></li></ul><p class=\"menu-label\"><a href=\"#question-section\">开放研究问题和未来方向</a></p><ul class=\"menu-list\"><li><a href=\"#问题场景理解\">场景理解</a></li><li><a href=\"#问题运动规划\">运动规划</a></li><li><a href=\"#问题决策\">决策</a></li><li><a href=\"#问题车辆控制\">车辆控制</a></li><li><a href=\"#问题车辆社会行为\">车辆社会行为</a></li><li><a href=\"#问题车辆通信\">车辆通信</a></li></ul><p class=\"menu-label\"><a href=\"#end\">结语</a></p>',15),k=[R];function w(e,t,c,a,r,i){return Object(b[\"p\"])(),Object(b[\"e\"])(\"aside\",x,k,512)}var M=c(\"2909\"),P=(c(\"d3b7\"),c(\"159b\"),c(\"7db0\"),Object(b[\"j\"])({name:\"TableOfContents\",props:[\"getSections\"],data:function(){return{current:\"\",links:[]}},mounted:function(){var e=this;this.observer=new IntersectionObserver((function(t){e.current=[],e.links=Object(M[\"a\"])(e.$refs.toc.querySelectorAll(\"a\")),t.forEach((function(t){var c=\"#\".concat(t.target.getAttribute(\"id\")),b=e.links.find((function(e){return e.getAttribute(\"href\")===c}));t.isIntersecting?null===b||void 0===b||b.classList.add(\"menu-item-active\"):null===b||void 0===b||b.classList.remove(\"menu-item-active\")}))}),{threshold:0}),document.querySelectorAll(\"#sections div[id],.chart[id],h2[id],img[id],article[id],.div[id]\").forEach((function(t){e.observer.observe(t)}))},beforeUnmount:function(){this.observer.disconnect()}}));c(\"1ffb\");const z=o()(P,[[\"render\",w]]);var T=z,I=c(\"c282\"),_=c.n(I),B=c(\"5ed8\"),G=c.n(B),H=c(\"2afe\"),Q=c.n(H),q=function(e){return Object(b[\"s\"])(\"data-v-ef3f40f0\"),e=e(),Object(b[\"q\"])(),e},F=q((function(){return Object(b[\"f\"])(\"section\",{id:\"foreword-section\",class:\"section is-medium\"},[Object(b[\"f\"])(\"h1\",{class:\"title\"},\"引言\")],-1)})),W=q((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"背景\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"1.1 背景\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 道路伤害是世界上死亡的主要原因之一。世界卫生组织（WHO）的最新报告显示，每年约有130万人死于道路事故(Be, 2021)。这一令人震惊的数字中有一半以上是弱势道路使用者(VRUs)，即行人、自行车和摩托车。其他研究表明，在所有VRU受害者中，行人仍是大多数受害者(El Hamdani et al., 2020)。自动驾驶和辅助驾驶人工智能焦点小组（FG-AI4AD）最近的一项研究强调，道路伤害已经是儿童死亡的主要原因，远远超过艾滋病毒和结核病造成的死亡。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 为了减少道路伤害并应对这些挑战，车辆网络（VANet）和自动驾驶汽车（AVS）越来越受到学术界和工业界的关注。预计这些技术将有效减少与自动驾驶相关的伤亡，并解决各种长期存在的交通挑战，即道路拥堵、行程延迟、停车和安全。在Singh（2015）中，据报道，所有车祸中有90%估计是人为失误造成的。智能交通系统（ITS）、计算系统和人工智能（AI）的最新进展为AVS的广泛引入铺平了道路。这为智能道路、智能交通安全和旅行者舒适度三个领域带来了新的机遇。研究人员估计，到2025年，将有800万辆自动驾驶汽车上路(Bay, 2021)。然而，由于过去发生的一些事件，尽管研究人员和汽车制造商仍在研究解决相关问题和剩余挑战的不同方法（Hussain and Zeadally, 2018），AVS的普及受到阻碍。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Autonomous Vehicle通常与self-driving vehicle互换使用，其能够感知其环境并在没有人类参与的情况下做出决策。自动驾驶汽车与道路旁基础设施和VRU相互合作收集和共享信息（Lamssaggad et al.2021）。AVS依靠车辆通信功能，在发生交通堵塞或事故时交换安全信息、交通状况和警告信息。无人驾驶车辆主要依靠传感器、执行器、复杂算法、人工智能技术和强大的计算资源来运行软件。因此，AVS能够处理复杂的道路情况，显著提高用户乘坐的安全性、舒适性和便利性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 美国汽车工程师学会（SAE）定义了6个级别的驾驶自动化，从全手动到全自动。0级和1级的特点是没有驾驶辅助，2级的定义是部分驾驶辅助，3级车辆具有“环境检测”能力，在没有人为干预的情况下，很少做出明智的决定，例如加速通过缓慢移动的车辆，而在4级（高驾驶自动化）中，驾驶员仍然可以选择在系统故障时手动控制，最后，第5级是全自动驾驶，在任何情况下都不需要驾驶员（Ma et al., 2020）。 \")])],-1)})),Z=q((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"国标自动驾驶等级分级\",src:_.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：国标自动驾驶等级分级\")],-1)})),E=q((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 为了使5级车辆成为可能，这需要车辆具有像人类驾驶员一样的“思考”、“感知”和“反应”的能力。由于人工智能在不同领域取得了许多最新成就，特别是在图像分类、目标检测和语音识别方面的成果，使得人工智能技术（如深度学习（DL）和强化学习（RL））越来越多地用于去实现5级车辆。基于DL的方法使许多研究能够解决AVS中各种挑战性问题，例如准确识别和定位道路上的障碍物、合适的车辆控制和运动规划。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 本文试图综述最近用于处理AVS中主要功能的基于人工智能的技术，即场景理解、运动规划、决策、车辆控制、社会行为和通信。我们的研究仅关注基于DL和RL的方法，因此忽略了基于浅层机器学习（ML）的技术，这是一个过去已经广泛研究的主题（Qayyum et al., 2019; Elassad et al., 2020）。传统的ML方法在实现AVS的主要功能（例如场景理解和运动规划）方面表现出了局限性。这促使我们将研究限制在DL和RL方法，以显示其在实现这些功能方面的潜力。、 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" DL和RL技术以其改善AVS任务的能力而闻名。例如，DL在目标检测方面表现出了良好的效果，这使其适合于自动驾驶中的场景理解。RL已成功应用于游戏和机器人等需要从环境中学习的其他领域。近年来，由于其取得了许多富有前景的结果，RL技术越来越受到AVS研究界的关注。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 回顾的安排如下：第一节讨论了现有的研究，并强调了我们想用当前研究填补的空白；介绍了我们的研究范围和研究方法。第二节简要介绍了应用于AVS的DL和RL方法。第三节介绍了AVS的不同传感器。第四节介绍了最近应用于AVS的基于DL的方法。第五节介绍了现有的解决自动驾驶问题的基于RL的方法。第六节提出了有待解决的研究问题和未来的研究方向。最后，第七节总结全文。 \")])],-1)})),U=q((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"自动驾驶中的六大任务\",src:G.a,width:\"800\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：自动驾驶中的六大任务\")],-1)})),K=q((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"现有综述\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"1.2 现有综述的介绍\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 文献中有几项研究研究了自主车辆技术的不同方面。 然而，这些研究大多没有详细讨论人工智能技术的使用，而DL和RL在不同应用中的使用则更少。Ohn-Bar and Trivedi (2016)讨论了下一代智能车辆中人类行为的理解、建模和预测，例如人与自动车辆内部或周围车辆之间的交互。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Xue et al. (2018) 研究了自动驾驶车辆中交通场景理解的功能，以及该功能如何帮助事件检测和意图预测。Elassad et al. (2020) 比较了机器学习（ML）模型和非ML模型之间的估计精度；他们确定了ML技术用于评估驾驶行为的优缺点。Qayyum et al. (2019) 讨论了与ML在车辆网络中的应用相关的挑战，并强调了由于采用ML方法而产生的不同安全问题 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Hussain and Zeadally (2018)全面回顾了自动驾驶汽车技术，并描述了自动驾驶汽车的设计和实施问题，例如自动驾驶汽车行业面临的技术和非技术挑战。此外，他们还介绍了自主车辆技术优化方向的ML和DL的最新发展。然而，这项工作涵盖了少数DL技术，仅限于几个方面，即感知、通信和控制，而完全忽略了RL技术。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Kuutti et al. (2020) 讨论了控制AVS的DL方法及其在复杂场景中的良好性能。作者介绍了应用于自主车辆控制的现有DL方法的优点和局限性。然而，它们没有涵盖自动驾驶的其他主要方面。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Rasouli and Tsotsos (2019)根据行人的人口统计、交通动态和环境条件，审查了不同的行人行为。然后，他们研究了分析十字路口行人行为的不同方法。然而，作者没有介绍DL和RL技术来改善行人和AVS之间的通信。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Ma et al. (2020) 分析了当前使用人工智能技术进行自动语音识别的实践，并讨论了与实现相关的挑战和问题。然而，他们并没有关注基于DL和RL的方法。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Claussmann et al. (2019) 回顾了运动规划技术；他们的重点是公路规划。他们讨论了运动规划中的主要算法及其在公路驾驶中的应用。然而，他们没有具体展示DL和RL在AVS领域中的作用。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Grigorescu et al. (2020) 研究了自动驾驶中使用的DL技术，并强调了该技术在场景感知、路径规划、行为仲裁和运动控制方面的优势和局限性。他们强调了当前有关自动驾驶人工智能架构设计的主要挑战。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Tong et al. (2019) 讨论了用于Vehicle toEverything（V2X）应用的人工智能方法，以及这些方法相对于传统算法的性能；他们也涵盖了人工智能在从不同来源获取信息方面的作用。然而，他们只关注车对车（V2V）和V2X中的信息共享问题。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Deb et al. (2018) 回顾了行人与全自动汽车的相互作用；他们强调了行人的新行为，这可能会导致潜在风险，需要在自动驾驶汽车上路之前加以识别。然而，他们没有研究DL和RL方法在实时准确检测行人意图方面的作用。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Feng et al. (2020) 提出了应用于自动驾驶的目标检测和分割系统。他们提出了与这些检测方法相关的挑战和开放性问题。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Arnold et al. (2019) 研究了3D物体检测方法，以及AVS中常用的传感器和数据集。另外作者讨论了基于传感器模式的最新贡献，并将其分为三大类：单目、基于点云和融合方法。然而，本次研究不包括DL方法。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Ning et al. (2021) 介绍了用于自动驾驶的现有人工智能架构。他们总结了这些架构的局限性，并引入了人工智能（H-AI）的概念；H-AI被认为是未来自主驾驶发展的一个新视角。他们还提出了未来需要解决的开放性研究挑战。然而，他们没有涵盖基于人工智能的解决方案，这些解决方案可能会在未来改善人工智能。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Severino et al. (2021) 讨论了道路标线、十字路口和路面对AVS操作的影响，尤其是在驾驶时检测环境。他们还提出了实施AVS系统所引起的一些技术问题。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 我们得出结论，现有研究没有全面涵盖DL和RL技术的使用，以解决AVS中与场景理解、运动规划、决策、车辆控制、社会行为和通信相关的主要问题。这促使我们通过介绍一项新的研究来填补文献中的这一空白，该研究致力于迄今为止应用于自主驾驶领域的大量DL和RL技术。表1总结了现有研究的覆盖范围。当前的研究揭示了DL和RL方法在自动驾驶汽车不同方面的潜力，并展示了在该领域可以实现的目标。与现有的自主驾驶研究不同，本文首次将重点放在DL和RL技术上，以实现AVS中的主要功能。 \")])],-1)})),X=q((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"现有综述文献间的对比\",src:Q.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：现有综述文献间的对比\")],-1)})),Y=q((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"本次研究的范围\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"1.3 本次研究的范围\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在本文中，我们全面综述了人工智能技术应用于自主汽车领域的最新研究进展。我们专门研究了DL和RL技术的优点和局限性。此外，我们还讨论了DL和RL算法的问题和挑战，这些问题和挑战需要进一步研究以实现5级自动驾驶。本文的主要贡献总结如下： \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 1） 我们简要介绍了自动驾驶的历史 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 2） 我们提出了自动驾驶汽车的详细分类，包括其组件、设计和实现。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 3） 我们详细描述了用于解决AVS中问题的DL和RL技术。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 4） 我们确定了在AVS中的DL和RL技术的优缺点。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 5） 我们提出并讨论了在AVS中的DL和RL技术相关的挑战和未决问题，需要进一步研究。 \")])],-1)})),J={class:\"content\"};function $(e,t){var c=Object(b[\"v\"])(\"number-papers4\"),a=Object(b[\"v\"])(\"number-papers3\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[F,W,Z,E,U,K,X,Y,Object(b[\"f\"])(\"div\",J,[Object(b[\"i\"])(c),Object(b[\"i\"])(a)])],64)}c(\"9e06\");const ee={},te=o()(ee,[[\"render\",$],[\"__scopeId\",\"data-v-ef3f40f0\"]]);var ce=te,be=function(e){return Object(b[\"s\"])(\"data-v-ef92eb9e\"),e=e(),Object(b[\"q\"])(),e},ae=be((function(){return Object(b[\"f\"])(\"section\",{id:\"trade-section\",class:\"section is-medium\"},[Object(b[\"f\"])(\"h1\",{class:\"title\"},\"自动驾驶的行业现状\")],-1)})),re={class:\"content\"};function ie(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"suan-li\"),s=Object(b[\"v\"])(\"market-size\"),j=Object(b[\"v\"])(\"distribution-rounds\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[ae,Object(b[\"f\"])(\"div\",re,[Object(b[\"i\"])(n),Object(b[\"i\"])(s),Object(b[\"i\"])(j)])],64)}var ne=function(e){return Object(b[\"s\"])(\"data-v-08cf7fee\"),e=e(),Object(b[\"q\"])(),e},se=ne((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 算力通常被用来指代芯片的性能，简单理解即算力越大，性能越好。随着激光雷达上车，自动驾驶计算平台突破1000TOPS，算力成为越来越多汽车厂家主打的汽车卖点之一。但高算力意味着在技术上要实现硬件、软件同步突破，需保留一定的冗余，还要在商业上实现技术和商业的平衡。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 自动驾驶的发展已经来到“上半场的下半段”，算力也已经成为判断汽车智能化程度的重要指标，车企希望通过突出算力值，让终端用户对车企的自动驾驶能力有更多认知。当前的算力理论上已经可以满足L2、L3自动驾驶系统需求，接下来重点是将场景和体验做得更好。 \")])],-1)}));function je(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[se,Object(b[\"i\"])(n,{id:\"chart-suanli\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])],64)}var Oe=Object(b[\"j\"])({name:\"SuanLi\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"高等级自动驾驶对芯片的算力要求(TOPS)\",left:\"center\"},tooltip:{trigger:\"axis\"},xAxis:{type:\"category\",data:[\"L1_L3\",\"L4\",\"L5\"]},yAxis:{type:\"value\"},series:[{data:[2.5,24,320],type:\"line\"}]});return{option:e}}});c(\"b69b\");const fe=o()(Oe,[[\"render\",je],[\"__scopeId\",\"data-v-08cf7fee\"]]);var le=fe,oe=function(e){return Object(b[\"s\"])(\"data-v-1ee966f5\"),e=e(),Object(b[\"q\"])(),e},de=oe((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 在政策、技术、市场需求以及资本等多方因素推动下，我国自动驾驶行业发展快速，场景应用和商业化落地成为自动驾驶供应商关键发力点。未来城市级智慧交通将连接交通参与者、载运工具、基础设施和运行环境，实现基于强计算、全感知、全融合的全链路综合交通服务与决策体系，将拥有比单个落地场景更加广阔的市场空间。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 随着车端、路端、云端智能布局持续完善，以及自动驾驶渗透率提升和市场机制的形成，加之产业链愈发成熟，预计2030年中国智慧交通市场规模将达到10.6万亿元。 \")])],-1)}));function ue(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[de,Object(b[\"i\"])(n,{id:\"chart-marketsize\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])],64)}var he=Object(b[\"j\"])({name:\"MarketSize\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"2020-2030年中国智慧交通市场规模预测（单位：亿元）\",left:\"center\"},tooltip:{trigger:\"axis\"},xAxis:{type:\"category\",data:[\"2021\",\"2021\",\"2022e\",\"2023e\",\"2024e\",\"2025e\",\"2026e\",\"2027e\",\"2028e\",\"2029e\",\"2030e\"]},yAxis:{type:\"value\"},series:[{data:[1448,3098,5165,8943,16410,23331,34592,47156,62955,83205,105963],type:\"line\"}]});return{option:e}}});c(\"022f\");const ve=o()(he,[[\"render\",ue],[\"__scopeId\",\"data-v-1ee966f5\"]]);var pe=ve,me=function(e){return Object(b[\"s\"])(\"data-v-2a9b77ba\"),e=e(),Object(b[\"q\"])(),e},ge=me((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},\" 我国自动驾驶行业投资热度较高，整车、自动驾驶解决方案、芯片和雷达等核心硬件、Robotaxi成为热门赛道。行业二八效应明显，头部企业持续获得资本支持。根据鲸准数据库，截至2021年11月30日，共收录1,764个自动驾驶相关项目。其中，种子轮至A轮项目221个，A+轮至C轮项目86个，C+轮至Pre-IPO项目15个，战略投资与并购项目328个，未融资项目1,114个，长尾明显。 \")],-1)}));function Le(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[ge,Object(b[\"i\"])(n,{id:\"chart-distributionrounds\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])],64)}var ye=c(\"22b4\"),Se=c(\"f95e\"),De=c(\"49bb\"),Ae=c(\"9394\"),Ce=c(\"2da7\"),Ne=c(\"ff32\");Object(ye[\"a\"])([Se[\"a\"],De[\"a\"],Ae[\"a\"],Ce[\"a\"],Ne[\"a\"]]);var Ve=Object(b[\"j\"])({name:\"DistributionRounds\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:[{text:\"中国自动驾驶项目融资轮次分布\",left:\"center\"}],tooltip:{trigger:\"item\",formatter:\"{a} <br/>{b} : {c} ({d}%)\"},legend:{orient:\"vertical\",left:\"left\",data:[\"种子轮至A轮\",\"A+轮至C轮\",\"C+轮至Pre—IPO\",\"战略投资与并购\",\"未融资\"]},series:[{name:\"融资轮次\",type:\"pie\",radius:\"55%\",data:[{value:221,name:\"种子轮至A轮\"},{value:86,name:\"A+轮至C轮\"},{value:15,name:\"C+轮至Pre—IPO\"},{value:328,name:\"战略投资与并购\"},{value:1114,name:\"未融资\"}],emphasis:{itemStyle:{shadowBlur:10,shadowOffsetX:0,shadowColor:\"rgba(0, 0, 0, 0.5)\"}}}]});return{option:e}}});c(\"d54d\");const xe=o()(Ve,[[\"render\",Le],[\"__scopeId\",\"data-v-2a9b77ba\"]]);var Re=xe,ke=Object(b[\"j\"])({name:\"TradeSection\",components:{SuanLi:le,MarketSize:pe,DistributionRounds:Re}});c(\"fd84\");const we=o()(ke,[[\"render\",ie],[\"__scopeId\",\"data-v-ef92eb9e\"]]);var Me=we,Pe={id:\"intro\",class:\"content\"},ze=Object(b[\"f\"])(\"div\",{class:\"B_title\"},null,-1),Te=Object(b[\"f\"])(\"div\",{class:\"card\"},[Object(b[\"f\"])(\"div\",{class:\"card-content\"},[Object(b[\"f\"])(\"div\",{class:\"intro\"},[Object(b[\"f\"])(\"p\",null,\" 近年来，自动驾驶汽车这一领域逐步成为当下的热点研究方向，因为这一技术能显著减少道路事故和人身伤害。智能交通系统（ITS）和人工智能（AI）的这两方面的最新进展，进一步为自动驾驶汽车（AVS）全面发展铺平了道路，也为智能道路、智能交通安全和旅行者舒适度这三个方面带来了新的机遇。在以往经典的控制方法之外，深度学习技术和强化学习技术也被用于这一领域。不同的研究者往往关注于不同方向的技术，而本文综述了最近所有主要功能基于人工智能的用于处理AVS的技术，即场景理解、运动规划、决策、车辆控制、社会行为和通信。我们仅关注基于深度学习和强化学习的方法;过去已被广泛研究的浅基（shallow based）技术不包括在内。通过这些研究，我们顺利建立了关于DL和RL算法的分类。最后，我们还提出了这方面仍然存在的诸多挑战，并分析了未来可能的研究方向。 \")])])],-1),Ie=[ze,Te];function _e(e,t,c,a,r,i){return Object(b[\"p\"])(),Object(b[\"e\"])(\"section\",Pe,Ie)}var Be=Object(b[\"j\"])({name:\"Begin\"});c(\"b8d2\");const Ge=o()(Be,[[\"render\",_e]]);var He=Ge,Qe=c(\"dfb9\"),qe=c.n(Qe),Fe=c(\"5b8a\"),We=c.n(Fe),Ze=c(\"38c0\"),Ee=c.n(Ze),Ue=c(\"1c40\"),Ke=c.n(Ue),Xe=function(e){return Object(b[\"s\"])(\"data-v-e9fc6b16\"),e=e(),Object(b[\"q\"])(),e},Ye=Xe((function(){return Object(b[\"f\"])(\"section\",{id:\"sensor-section\",class:\"section is-medium\"},[Object(b[\"f\"])(\"h1\",{class:\"title\"},\"自动驾驶技术概要\")],-1)})),Je=Xe((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"自动驾驶解决方案\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"3.1 自动驾驶解决方案\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 自动驾驶涵盖多种解决方案。非全栈解决方案主要针对单独的技术或产品提供服务；全栈解决方案需要全部掌握自动驾驶领域最核心最关键的技术，从数据获取、底层算力、软硬件开发等层面形成闭环，实现车端、路端、云端融合一体化发展，拥有更好的性能和更强的可控性。一站式解决方案除了具备全栈解决方案的技术优势外，还能够提供前中后端一体化的运营服务，构建一站式大生态，打造更深的护城河。 \")])],-1)})),$e=Xe((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"自动驾驶解决方案图\",src:qe.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：自动驾驶一站式解决方案\")],-1)})),et=Xe((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"自动驾驶汽车的传感器\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"3.2 自动驾驶汽车的传感器\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 人口增长导致车辆数量增加，对当前交通基础设施（如停车场、充电站和加油站）造成沉重负担。车辆数量的持续增加是导致交通问题包括空气污染、噪音污染、道路撞车和交通堵塞。为了解决这些问题，研究人员一直在开发AVS。目标是消除或至少减少由人为驱动因素引起的问题。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" AVS被定义为智能代理，可以通过安装在车辆上的不同传感器感知其环境。当人类使用感官（如视觉和听觉）驾驶时，AVS使用传感器（如摄像机和雷达）。传感器的质量在构建成功的AVS中起着关键作用。例如，如果从相应传感器收集的数据不可靠，则最佳感知算法的性能可能较差。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 传感器的作用是测量或检测环境的某些特性或这些特性随时间的变化。传感器大致分为两类： \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" （a）外部感知传感器：它们记录车辆周围环境的特性（例如，摄像机和光探测与测距（LIDAR））； \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" （b） 本体感觉传感器：它们记录车辆本身的特性（例如全球导航卫星系统（GNSS）位置和车轮里程表）。 \")])],-1)})),tt=Xe((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"自动驾驶汽车上的传感器\",src:We.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：自动驾驶汽车上的传感器\")],-1)})),ct=Xe((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 自动驾驶中最常见和最广泛使用的传感器是摄像头。摄像机是一种被动的集光传感器，可以捕捉场景的丰富而详细的信息。摄像机的质量由各种指标决定，例如分辨率和视野。分辨率是创建图像并影响其质量的像素数。视野由摄像机可见的水平和垂直角度范围定义，可以通过镜头选择和变焦来改变。摄像机的动态范围由图像中最暗色调和最亮色调之间的差异定义。高动态范围对于自动驾驶车辆至关重要，因为在夜间驾驶时会遇到高度可变的照明条件。具有重叠视野和对齐图像平面的两个摄像机的组合称为立体摄像机；它们生成场景的视差图，用于估计每个像素的深度（Thakur，2018）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" AVS中的第二个关键传感器是激光雷达。它发射光束。通过测量返回的光量和光束的飞行时间，可以估计反射物体的折射率。激光雷达生成三维点云地图，用于评估场景几何体。激光雷达通常由一些关键指标控制，如信源数量、每秒可收集的点数和视野（Bussemaker，2014）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 无线电探测和测距（雷达）传感器的使用时间比激光雷达长。它们能够强有力地检测环境中的大型物体，在恶劣天气下尤其有用，因为它们大多不受雨水影响。雷达传感器的特点是其探测范围、视野以及位置和速度测量精度（Curry，2005）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 超声传感器在AVS中也很重要；他们用声波测量距离。它们特别适用于停车场景，在这种场景中，车辆需要靠近其他车辆移动（Curry，2005）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 车载工业中的主要本体感知传感器之一是全球导航卫星系统，如GPS或伽利略。全球导航卫星系统可以测量车辆的位置、速度，有时还可以测量航向。惯性测量单元（IMU）测量车辆的角转速和加速度。另一个重要的本体感觉传感器是车轮里程表；它跟踪车轮的旋转速度，并使用这些信息来估计车辆的速度和航向变化率（Reinholtz et al, 2007）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 通常，在识别环境后，AVS执行许多任务，包括目标检测、规划、决策、控制速度和驾驶，而无需任何人为干预。 \")])],-1)})),bt=Xe((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"现代自动驾驶技术实现流程\",src:Ee.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：现代自动驾驶技术实现流程\")],-1)})),at=Xe((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"自动驾驶技术构架图\",src:Ke.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：自动驾驶技术构架图\")],-1)}));function rt(e,t){return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[Ye,Je,$e,et,tt,ct,bt,at],64)}c(\"6afc\");const it={},nt=o()(it,[[\"render\",rt],[\"__scopeId\",\"data-v-e9fc6b16\"]]);var st=nt,jt={id:\"end\",class:\"content\"},Ot=Object(b[\"g\"])('<hr class=\"custom\"><h1>总结</h1><div class=\"card\"><div class=\"card-content\"><div class=\"intro\"><p> 我们分析了近十年来在深度学习、强化学习、自动驾驶等方面的研究进展，同时分析了许多论文的具体方向。我们发现，随着社会发展，自动驾驶的需求日渐提高，自动驾驶汽车的研究越来越受到重视，也出现了许多新的研究成果。 <br><br> 在道路上引入自动驾驶汽车的目的是让驾驶者解放自己，避免因为人的失误出现的意外，使车辆能够在没有人为干预的情况下自动驾驶。自动驾驶汽车可以显著减少与汽车相关的死亡和伤害，并解决各种长期存在的交通挑战，如道路拥堵、行车延误、安全泊车等等。自动驾驶为智能道路、智能交通安全和舒适旅行提供了新的机遇。 <br><br> 智能交通系统、计算系统和人工智能的最新进展推动了自动驾驶技术的发展并为其铺平了道路。但现有研究很少关注深度学习和强化学习技术在解决自动驾驶的场景理解、运动规划、决策、车辆控制、社会行为和沟通问题中的作用。 <br><br> 在本文中，我们调查了这方面研究工作的相关文献。这些研究旨在使用深度学习和强化学习技术解决自动驾驶的主要问题。我们对迄今为止的针对解决自动驾驶问题的深度学习和强化学习技术进行了分类。 <br><br> 我们说明了深度学习和强化学习在自动驾驶技术不同方面的潜力，并进一步展望了在这一领域可以实现的目标。我们还分析了深度学习和强化学习为自动驾驶带来的改进，这些改进克服了传统机器学习技术的局限性。 <br><br> 最后，我们分析了现有的主要研究挑战，并指出了开发完全自动驾驶汽车的未来可能的研究方向。相信随着时代的发展，自动驾驶领域的未来一定会越来越好。 </p></div></div></div>',3),ft=[Ot];function lt(e,t,c,a,r,i){return Object(b[\"p\"])(),Object(b[\"e\"])(\"section\",jt,ft)}var ot=Object(b[\"j\"])({name:\"End\"});c(\"59b0\");const dt=o()(ot,[[\"render\",lt]]);var ut=dt,ht=c(\"5f28\"),vt=c.n(ht),pt=c(\"33ba\"),mt=c.n(pt),gt=c(\"c8de\"),Lt=c.n(gt),yt=c(\"cc32\"),St=c.n(yt),Dt=c(\"eb63\"),At=c.n(Dt),Ct=Object(b[\"f\"])(\"section\",{id:\"RL-section\",class:\"section is-medium\"},[Object(b[\"f\"])(\"h1\",{class:\"title\"},\"自动驾驶与强化学习\")],-1),Nt={class:\"content\"},Vt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 尽管深度学习技术在自动驾驶中取得了令人鼓舞的成果，但是仍然远远不能实现自动驾驶汽车的完全自主，特别是在决策、运动规划和车辆控制方面。基于深度学习的技术有其固有的缺点，其中的主要缺点是需要数据集来学习预测模型，并且不能自校正累积误差。为了克服这些问题，研究人员正在尝试应用强化学习等其他技术，这些技术可以无需收集数据并且直接从环境中学习。强化学习模型能够通过不断的试错来学习如何执行目标任务。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在这一部分，我们涵盖了现有的基于强化学习的方法，旨在解决自动驾驶问题，包括：(1) 决策；(2) 运动规划；(3) 车辆控制；(4) 自动驾驶汽车的社会行为。这些是自动驾驶应用的主要领域。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在讨论强化学习在自动驾驶任务中的应用之前，我们简要回顾一下自动驾驶环境中的状态空间、动作空间和奖励机制。 \")])],-1),xt={class:\"content\"},Rt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"状态空间、动作空间和奖励机制\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"5.1 状态空间、动作空间和奖励机制\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 为了成功地将强化学习应用于自动驾驶任务，设计适当的状态空间、动作空间和奖励函数非常重要。Leurent等人（2018）对自动驾驶研究中使用的不同状态和动作表示法进行了综合评述。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 自动驾驶汽车通常使用的状态空间特征包括：自身的位置、航向和速度，以及自车载传感器视野范围内的其他障碍物。为了避免状态空间维度的变化，通常会围绕自动驾驶汽车建立笛卡尔坐标系或极坐标系下的占用网格。这种操作进一步增加了车道信息，例如车道号、路径曲率、自身车辆过去和未来的轨迹；纵向信息，例如碰撞时间(TTC)；以及最后的场景信息，例如交通法规和信号位置。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 使用原始传感器数据，如相机图像、激光雷达、雷达等，会为我们提供更好的上下文信息，然而使用压缩的抽象数据大大降低了状态空间的复杂性。介于这两者之间的中等大小的状态空间表示，如2D鸟瞰图（BEV）是无法从传感器获得的，但是它仍然接近场景的真实空间状态。下图是自顶向下视图的图示，显示出了网格、过去和未来的轨迹以及关于场景的语义信息，例如交通信号的位置。这种状态空间表示保留了道路的空间布局，而基于图形的表示则无法保留。 \")])],-1),kt=Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"2D鸟瞰图\",src:vt.a,width:\"1000\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：2D鸟瞰图\")],-1),wt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 自动驾驶汽车控制策略必须控制许多不同的执行器。用于车辆控制的连续值执行器包括转向角、节气门和制动器。其他执行器，例如齿轮的变化是离散的。为了降低复杂性并允许应用仅适用于离散动作空间（如DQN）的强化学习算法，可将连续值执行器（如转向角、节气门和制动器）的调节范围划分为一系列间隔区间大小相等的离散值，以将动作空间均匀离散化。此外，有人建议在对数空间进行离散化，因为实际驾驶中选择的转向角多数都靠近中心值。然而，离散化也有其自身的缺点，如果动作之间的步长值太大，可能会导致车辆运动轨迹不平稳或不稳定。此外，当选择用于执行器的离散值数量时，我们需要在具有足够的离散值以实现平滑控制和不具有太多离散值以提升控制效率之间权衡。作为离散化的替代方案，我们可以选择直接学习策略的DRL算法来处理连续值执行器（例如DDPG）。时间抽象选项框架（Sutton等人，1999）也可以用来简化选择动作的过程，该框架选择options而不是某个基本动作。这些options代表着一个子策略，它可以将一个基本动作扩展到多个时间步长。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 为应用于自动驾驶技术的强化学习算法设计奖励函数仍然是一个悬而未决的问题。为自动驾驶任务设计的奖励标准包括：朝向目的地行进的距离、自我车辆的速度、使自我车辆保持静止、与其他道路使用者或场景物体的碰撞、人行道上的违规行为、保持在车道上、以及在避免极端加速、制动或转向和遵守交通规则的同时保持舒适和稳定性。 \")])],-1),Mt=Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"自动驾驶模拟器\",src:mt.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：自动驾驶模拟器\")],-1),Pt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"模拟器和场景生成工具\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"5.2 模拟器和场景生成工具\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 自动驾驶数据集中的训练集包含不同场景的图像和标签对，我们能够利用它来实现监督学习。强化学习算法需要一个特殊环境，其中“状态-动作对”需要是可恢复的，同时需要分别对车辆状态、环境以及环境和主体的运动和动作的进行随机性建模。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 各种模拟器被广泛地用于训练和验证强化学习算法。各种高保真感知模拟器能够模拟照相机、激光雷达和雷达，部分模拟器也能够提供车辆状态信息和运动信息。Rosique等人（2019）为读者提供了自动驾驶领域中使用的传感器和模拟器的完整综述。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在现实世界中进行昂贵的评估之前，自动驾驶算法所学习的驾驶策略需要先在模拟环境中进行测试。Cutler等人（2014）提出了一种多保真度强化学习（MFRL）框架，该框架让我们能同时使用多个模拟器。在MFRL框架中，一系列保真度越来越高的模拟器被用于表示状态动力学（以及计算成本），这提高了我们训练和验证强化学习算法的能力，同时让我们能够以更少的代价找到与真实世界最为接近的策略。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" CARLA Challenge 是German Ros等人（2019）年推出的一个基于CARLA模拟器的自动驾驶任务竞赛，其中具有国家公路交通安全管理局报告中描述的碰撞前场景。该竞赛系统在关键场景中对自动驾驶算法进行评估，例如：自身车辆失去控制、自身车辆对视野外的障碍物做出反应、变道以避开缓慢的前方车辆等。自动驾驶算法的得分为在不同赛道上行驶的总距离的一个函数，并且违法行为将会扣除部分总得分。 \")])],-1),zt={class:\"content\"},Tt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"强化决策\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"5.3 决策\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 通过从经验和环境中学习，强化学习技术目前正在为自动驾驶汽车提供更好和更精确的信息。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" You等人（2018）提出马尔可夫决策过程（MDP）对自动驾驶汽车与周围车辆的相互作用进行建模。MDP允许自动驾驶汽车在超车或尾随另一辆车时，根据道路结构做出适当的决定。不过，他们的方法仍需要在不同的场景中进行更多的测试来验证。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Hoel等人（2018）提出了一种在高速公路上做出决策（如变道、加速和制动）的方法。他们利用Deep Q Network (DQN)来训练他们的提案并预测正确的决策。不过，他们的方法并不能在其他情况下保证安全性（如环形路和十字路口）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 无信号交叉口被认为是自动驾驶汽车做出准确且及时决策的最具挑战性的场景之一。Isele等人（2018）提出了一种基于DQN的方法来导航自动驾驶汽车安全的通过交叉口。他们提案的结果优于传统方法（Hafner等人，2013；Alonso等人，2011）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Okuyama等人（2018）将卷积神经网络和强化学习相结合，在具有车道标志和静态障碍物(例如人、停止的车辆)的模拟环境中训练自动驾驶汽车。CNN利用由自动驾驶汽车的前置摄像头拍摄的图像，以提取道路的主要状态特征。这些特征被反馈给DQN以预测下一步的行动。不足的是，他们的方法没有考虑动态障碍。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Hoel等人（2019）提出了一种策略决策方法，该方法结合了蒙特卡罗树搜索（MCTS）和强化学习算法，以在两种高速公路驾驶情况下控制自动驾驶汽车（包括连续高速公路驾驶和退出高速公路）。他们的提案在模拟高速公路环境中进行了测试，初步结果显示了RL和MCTS相结合的有效性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Hoel等人（2020）针对三车道的单向高速公路，提出了另一种用于自动驾驶汽车的策略决策方法。他们使用强化学习来估计驾驶行为，例如加速、留在车道上、左转、右转和刹车。结果表明，随着时间的推移，他们的方法学会了做出有效的决策。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Ye等人（2019）研究了一种强化学习方法，允许自动驾驶汽车在一条直行道路上进行车道变更(无信号灯控制)，该算法已经在模拟环境中利用Q学习进行了训练。然而，他们的方法需要在复杂的场景中进行更多的测试。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Sun等人（2020）提出了一种基于强化学习的针对重型自动驾驶汽车的决策方法，即深度确定性策略梯度（DDPG）算法。该网络接收自动驾驶汽车的信息状态（包括速度、与其他车辆的距离）然后做出决定。模拟结果显示，他们的方法学会了通过环境快速做出决定。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Duan等人（2020）提出了一种方法来训练自动驾驶汽车从四周环境中学习并做出三种决策（包括车道变换、右车道变换和左车道变换）。然而，他们只关注高速公路的情况，而没有处理其他情况（如交叉路口和城市交通）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen等人（2019a）提出了一种在车辆密集的环形交叉口上控制自动驾驶汽车的方法。他们的方法从传感器获取周围每个物体的信息（例如速度和位置）；该方法使用DQN预测正确的动作。他们在Carla模拟器中模拟了他们的算法，模拟结果显示出该方法在解决环形交叉口驾驶情况的乐观前景。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Wolf等人（2017）使用DQN在模拟环境中训练自动驾驶汽车。利用摄像头，自动驾驶汽车识别道路并采取转弯动作（例如，左、半左、直、半右和右）。然而，他们的建议需要考虑到静态和动态的障碍。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Likmeta等人（2020）提出了针对三种场景（变道、交叉路口、环形交叉口）的决策方法。他们使用强化学习来训练自动驾驶汽车在不同的情况下做出决策。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Huang等人（2019b）提出了一种基于强化学习的方法，通过利用状态信息（例如，车辆速度和道路距离）训练自动驾驶汽车预测所需的决策，以采取动作（加速、减速和转向）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Hu等人（2019）提出了一种基于强化学习的方法，在两个场景的融合中控制自动驾驶汽车的决策方法。他们的方案在所有测试场景中实现了零碰撞。然而，这种方法并不能保证安全，特别是在机动性较高的实际交通中。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Wang等人（2020）提出了一种在复杂高速道路中生成驾驶策略的方法。基于反馈给DQN的传感器信息（例如，车辆位置和速度）来学习如何为复杂高速公路中的每辆车辆做出决策（加速、减速、保持车道、右转和左转）。模拟结果表明，该方法提高了道路的安全性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Zhou等人（2021）提出了一种混合交通中自动驾驶车辆协同变道的多智能体强化学习（MARL）框架。其中每一辆自动驾驶汽车根据相邻的自动驾驶汽车和人类驾驶汽车的运动做出车道变换决策。该方法提出了一种多目标奖励函数，以结合燃油效率，驾驶舒适性和自动驾驶的安全性。实验结果表明，该方法在效率、安全性和驾驶员舒适度方面均优于现有常见方法。 \")])],-1),It=Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"强化学习决策流程\",src:Lt.a,width:\"700\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：强化学习决策流程\")],-1),_t=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"强化运动规划\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"5.4 运动规划\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Nosrati等人（2018）提出了一种基于强化学习的分层方法，使用DQN在多车道的道路上控制自动驾驶汽车。该方法的目标是安全地避开障碍物(如其他车辆和摩托车)。这项工作还需要在复杂的场景中进行测试(例如，城市交通和十字路口)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Paxton等人（2017）研究了一种基于强化学习的蒙特卡罗树搜索（MCTS）方法，用以生成长期运动规划。该方法主要是让自动驾驶汽车避免在交叉路口发生碰撞。然而，该方法还需要在其他复杂的环境中进行更多的测试。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Zhu等（2018）模拟了自动驾驶汽车在与环境交互作用下的学习过程。基于来自四个摄像机视图的数据，结果表明强化学习算法能够适应不同的交通状况。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" You等人（2019）对自动驾驶汽车和高速公路交通之间的相互作用进行了建模，并考虑了道路几何结构。基于Q学习，自动驾驶汽车从环境中学习动作（例如，车道变换、速度保持、加速和制动）。仿真结果表明，该方法能够适应多车道多车辆的交通状况。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Fayjie等人（2018）提出了一种运动规划方法，用于在两种场景下控制自动驾驶汽车（包括城市交通和五车道的高速公路）。该方法使用CNN提取来自相机和激光雷达的数据特征。这些特征被输入给DQN以估计正确的动作（例如，继续前进、向左、向右、加速和刹车）。然而，该方法没有考虑到其他道路参与者。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen等人（2020a）提出了一种可解释的端到端方法来解决复杂城市场景中的自动驾驶问题(交叉口和环形交叉口)。强化学习模型将相机和激光雷达的图像作为输入，并避免密集交通中的碰撞。实验结果表明，该方法优于其他强化学习方法（Mnih等人，2015；Lillicrap等人，2015年；Fujimoto等人，2018；Haarnoja等人，2018)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Cao等人（2020）提出了一种基于强化学习的高速公路出口规划方法。该方法基于对环境的观察来估计离开高速公路的预期。结果显示，该方法将离开高速公路的成功率增加了5%到50%。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen等人（2020c）提出了一种基于DQN控制自动驾驶汽车的方法。CNNs和LSTM一起用于从摄像机图像中提取状态信息。这些特征被输入到DQN以学习运动命令，例如直行、右转和在十字路口左转。仿真结果表明，与DDQN方法相比该方法学习速度更快（Wang等，2016）。然而，该方法没有考虑障碍物（例如，行人、骑自行车的人和其他车辆）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 即使深度学习能够从专业驾驶员的停车数据中学习，人类的知识也不能保证高效停车。为此，Zhang等人（2020a）提出了一种强化学习方法，使用MCTS来训练自动驾驶汽车学习停车策略。该方法实现了高效停车。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Wang等人（2020a）提出了一种运动规划方法，该方法检测车辆轨迹中的障碍物，并使用强化学习方法自主地避开它们。他们在多车道和不同交通密度的道路上训练了他们的方法。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Lu等人（2020）利用MDP来实现自动驾驶汽车处理复杂场景（包括没有交通信号的左转和多车道合并）。该方法的目标是训练自动驾驶汽车以实现在这两个场景中成功导航。实验结果证明了该方法的有效性和高效性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Kasra等人（2021）提出了一种基于强化学习的方案，用于解决存在不确定性的情况下进行自动驾驶汽车的运动规划。该方案专注于解决传感和感知的不确定性，这是由有限的视野、遮挡和感知范围引起的。该方案应用于两种不同的强化学习算法用于验证，Soft Actor-Critic和DQN。与传统的强化学习算法相比，该方法产生了更好的运动规划行为。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Tung等人（2022）提出了一个基于学习的规划器DriveIRL，该规划器使用逆强化学习（IRL）在密集的城市交通中驾驶汽车。该规划器生成一组不同的轨迹建议，使用轻量级的且可解释的过滤器筛选这些轨迹，之后使用学习的模型对剩余的每个轨迹进行评分，最佳轨迹由自动驾驶汽车的低级控制器进行跟踪。他们在真实数据集上训练评分轨迹模型，并且在交通繁忙的拉斯维加斯大道进行了自动驾驶展示。 \")])],-1),Bt=Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"强化学习运动规划方法\",src:St.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：强化学习运动规划方法\")],-1),Gt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"强化车辆控制\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"5.5 车辆控制\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 强化学习的目标是找到一个最佳的控制指令(例如，改变速度，刹车，或加速) ，通过一种迭代的方法探索环境。环境根据自动驾驶汽车当前的行为来奖励并纠正未来的错误。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li 等人（2017）提出了一种在多车道高速公路上控制自动驾驶汽车行驶的方法。该方法使用强化学习执行三个控制命令（减速、硬减速和维护）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li 等人（2019a）将感知模块和控制模块相结合。感知模块以道路图像作为CNNs的输入提取状态信息特征。这些特性被输入给DQN来从环境中学习转向控制。该方法在不同的轨道上进行了测试，初步结果显示自动驾驶汽车学会了有效的控制。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Zhu等人（2020）提出了一种基于深度确定性策略梯度（DDPG，lillicrap 等，2015）控制自动驾驶汽车速度以避免碰撞的强化学习方法。仿真结果表明了该方法在安全性和舒适性方面的有效性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Amini 等人（2020）提出了一种强化学习方法，用于在不同的天气条件（晴天和雨天)、光照情况(白天和夜晚)和道路类型(乡村和高速公路)下控制自动驾驶汽车。自动驾驶汽车会观察物体（例如树木、汽车和行人），并且主动绕开它们。仿真结果表明了该方法在实际道路上的自适应能力。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Guo等人（2020）提出了一种基于强化学习的方法，用于在三车道高速公路中横向控制自动驾驶汽车。该方法的目标是安全地实现变道。结果表明，该方法改善了交通流量和交通容量。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Wu等人（2020）研究了一种差分变速极限（DVSL）方法，用于在五车道高速公路中控制自动驾驶汽车的速度。DVSL 被建模为一个MDP问题，并且利用SUMO模拟器来训练自动驾驶汽车，使其从与环境的相互作用中学习。试验结果表明，该方法提高了高速公路行驶的安全性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen等人（2020b）提出了一个使用蒙特卡罗树搜索（MCTS）的强化学习方法，用于控制自动驾驶汽车执行不同的机动以避免碰撞。他们将控制过程建模为MDP问题，并使用MCTS来产生转向角。该方法显示了更高的控制稳定性和更高的避免意外事件的成功率。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Zhang等人（2018）研究了一种基于DQN和Double-Q学习的自动驾驶汽车速度控制方法。他们用来自真实世界的数据训练该方法，结果显示该方法在价值准确性方面有所改进。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Baheri等人（2020）提出了一种在城市驾驶中保持车道的方法。他们的建议是从环境中提取状态观测值，并使用强化学习在CARLA模拟器中训练自动驾驶汽车。他们在两个城镇和不同的天气条件下对自动驾驶汽车进行了模拟，并且成功地完成了车道保持任务。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Bouton等人（2020）使用强化学习和博弈论解决密集交通中的机动问题。该方法被建模为MDP问题，以实现自动驾驶汽车在合并场景中保持或改变车道。结果表明，与现有方法相比，该方法能够更有效地学习。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Ye等人（2020）提出了一种高速公路自动换道策略，该策略使用了最近策略优化（PPO）和强化学习。利用车辆和周围车辆的状态，自动驾驶汽车学习如何避免碰撞和实现平稳机动。测试结果表明，该方法可以学习如何有效、安全地执行车道变换操作。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Toromanoff等人（2020）提出了一种强化学习方法来解决复杂情况（包括车道保持、行人和车辆避让）。他们使用CARLA模拟器来训练模型，只使用一个摄像头来观察周围环境以实现城市驾驶。他们使用DQN来训练自动驾驶汽车从如何处理以前的情况中学习。仿真结果表明，该方法可以推广到未知环境。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 类似地，Jaritz等人（2018）仅使用一个摄像头来观察环境，利用一种强化学习结构（Mnih等人，2016）让自动驾驶汽车学习如何估计控制命令（转向、加速、制动）。他们用不同的道路结构（例如，转弯和山丘）、图形学（例如，季节和位置）和物理学（例如，道路附着力）来处理轨迹。然而，该方法没有考虑碰撞。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Wang等人（2018）研究了在单向三车道的高速公路上控制自动驾驶汽车进行车道变换的问题。该方法考虑到了周围车辆的行为，并使用Q学习来实现车道变换。实验结果显示了该方法在学习车道变换方面的乐观前景。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Liang等（2018）提出了一种可控模仿强化学习(CIRL)方法，利用DDPG方法（Lillicrap等人，2015）和CARLA模拟器在复杂场景中（车辆和行人）控制自动驾驶汽车。该方法的结果优于现有的强化学习技术（Dosovitskiy等人，2017）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Shi等人（2022）提出了一种基于双边控制模型（BCM）的深度强化学习（DRL）框架，用于实现优于人类驾驶策略的汽车跟随。该方法同时考虑前后车辆，并将双边信息集成到状态和奖励函数中。此外，该方法使用分散的多智能体强化学习框架为每个智能体生成相应的控制动作。仿真结果表面，该方法学习的策略优于人类驾驶策略。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Edoardo等人（2022）提出了一种基于强化学习的方法，用于控制自动驾驶赛车实现稳健的循迹驾驶。该方法受到上层运动规划器所生成的轨迹的限制。该方法的利用强化学习的启发式特性，同时利用传统规划方法中分层控制结构的可靠性。模拟实验表明，该方法实现了更低的碰撞概率，并且实现了比端到端方法更低的单圈时间。 \")])],-1),Ht=Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"强化学习车辆控制流程\",src:At.a,width:\"700\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：强化学习车辆控制流程\")],-1),Qt=Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"强化社会行为\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"5.6 车辆社会行为\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 任何自动驾驶模型系统都必须能够实时处理城市交通中的道路使用者行为。在这方面，强化学习方法证明了其在理解道路使用者行为并做出正确决策的能力。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Saleh等人（2018）提出了城市交通环境中的行人意图预测问题。基于对行人过去轨迹的观察，他们的方法使用循环神经网络和强化学习来预测行人的未来行为。实验结果显示，该方法显著改进了预测效果。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li等人（2020a）提出了一种基于强化学习的方法，使用MDP识别行人行为并避开行人。该方法考虑了车辆和行人都在同一条结构化双车道道路上的情况。车辆在道路上行驶，而一名行人正在等待过马路，这种情况可能会造成事故，该方法的目标是避免这种碰撞。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li等人（2020b）提出了一种在复杂场景下估计未来行人位置的强化学习方法。该方法的目标是训练自动驾驶汽车学会识别道路上每个行人的未来姿态。该方法的结果在预测精度方面优于现有的方法（Van den Berg等人，2008；Chen等，2017b；Everett等人，2018；Gupta等人，2018）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Nasernejad等人（2021）将交叉口行人和自动驾驶汽车之间的相互作用建模为MDP问题。该方法能够让自动驾驶汽车根据行人在环境中的行为来避开行人。然而，该方法仅限于行人和车辆的相互作用，而其他相互作用(例如自行车)也应该被考虑。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Wang等人（2021）提出了一种基于协商感知运动规划的强化学习框架。该框架采用强化学习来调整运动规划器的驾驶风格，通过动态修改运动规划器的预测视野长度，自适应地应对复杂环境中的不同事件。该框架将自动驾驶汽车与其他交通参与者之间的交互建模为马尔可夫决策过程。他们将该方法应用在模拟和现实世界中的狭窄车道导航，结果现实该方法优于常见的其他方案。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Britod等人（2022）提出了一种在密集交通场景中的交互感知模型。该方法通过深度强化学习模型来学习一种交互感知策略，并用于推理道路上其他车辆的驾驶意图，进一步指导自身车辆的动态规划。该方法在两种模拟环境中（高速公路合并和无保护的左转弯）进行了实验。结果表明，该方法减少了碰撞次数，并提高了成功率。 \")])],-1);function qt(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"keywords-reinforcement\"),s=Object(b[\"v\"])(\"keywords-deepreinforcement\"),j=Object(b[\"v\"])(\"publication\"),O=Object(b[\"v\"])(\"number-papers1\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[Ct,Object(b[\"f\"])(\"div\",Nt,[Object(b[\"i\"])(n),Object(b[\"i\"])(s)]),Vt,Object(b[\"f\"])(\"div\",xt,[Object(b[\"i\"])(j)]),Rt,kt,wt,Mt,Pt,Object(b[\"f\"])(\"div\",zt,[Object(b[\"i\"])(O)]),Tt,It,_t,Bt,Gt,Ht,Qt],64)}var Ft=c(\"6644\"),Wt=c.n(Ft),Zt=function(e){return Object(b[\"s\"])(\"data-v-ce02c39c\"),e=e(),Object(b[\"q\"])(),e},Et=Zt((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"h\"])(\" 强化学习是机器学习的一个分支，具有以下特点：\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" a. 无特定数据，只有奖励信号;\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" b. 奖励信号不一定实时;\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" c. 主要研究时间序列的数据，而不是独立同分布的数据;\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" d. 当前行为影响后续数据; \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\"对比其他机器学习方法，监督学习和无监督学习都需要静态的数据，不需要与环境交互，数据输入到相关函数训练就行。而且对于有监督学习和无监督学习来说，有监督学习强调通过学习有标签的数据，预测新数据的标签，无监督学习更多是挖掘数据中隐含的规律。强化学习不需要给出“正确”标签作为监督信息，只需要给出策略的(延时)回报，并通过调整策略来取得最大化的期望回报。 \")])],-1)})),Ut=Zt((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"强化学习算法流程图\",src:Wt.a,width:\"600\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：强化学习算法流程\")],-1)}));function Kt(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[Et,Ut,Object(b[\"i\"])(n,{id:\"chart-keywords-reinforcement\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])],64)}var Xt=Object(b[\"j\"])({name:\"KeywordsReinforcement\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"强化学习相关论文数量\",left:\"left\"},tooltip:{trigger:\"axis\"},xAxis:{type:\"category\",data:[\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]},yAxis:{type:\"value\"},series:[{data:[811,821,852,833,843,1011,2204,4776,8081,8016],type:\"line\"}]});return{option:e}}});c(\"494d\");const Yt=o()(Xt,[[\"render\",Kt],[\"__scopeId\",\"data-v-ce02c39c\"]]);var Jt=Yt;function $t(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"d\"])(n,{id:\"chart-keywords-deepreinforcement\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])}var ec=Object(b[\"j\"])({name:\"KeywordsDeepreinforcement\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"深度强化学习论文数量\",left:\"left\"},tooltip:{trigger:\"axis\"},xAxis:{type:\"category\",data:[\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]},yAxis:{type:\"value\"},series:[{data:[5,9,10,8,14,164,355,898,2005,2203],type:\"line\"}]});return{option:e}}});c(\"be4c\");const tc=o()(ec,[[\"render\",$t],[\"__scopeId\",\"data-v-4f0b87ee\"]]);var cc=tc;function bc(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"d\"])(n,{id:\"chart-publication\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])}var ac=c(\"3620\"),rc=c(\"4cb5\");c(\"cd12\");Object(ye[\"a\"])([Se[\"a\"],ac[\"a\"],rc[\"a\"],Ae[\"a\"],Ce[\"a\"],Ne[\"a\"]]);var ic=Object(b[\"j\"])({name:\"Publication\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"自动驾驶领域中强化学习相关论文数量\",left:\"left\"},tooltip:{trigger:\"axis\"},xAxis:{type:\"category\",data:[\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]},yAxis:{type:\"value\"},series:[{data:[0,0,1,2,1,5,10,89,140,153],type:\"line\"}]});return{option:e}}});c(\"a462\");const nc=o()(ic,[[\"render\",bc],[\"__scopeId\",\"data-v-48311850\"]]);var sc=nc;function jc(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"d\"])(n,{id:\"number-papers-1\",class:\"chart\",autoresize:!0,option:e.Option},null,8,[\"option\"])}var Oc=Object(b[\"j\"])({name:\"NumberPapers\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({animationDuration:5e3,dataset:[{source:[[\"年\",\"CARLA\",\"TORCS\"],[2018,20,10],[2019,73,11],[2020,131,8],[2021,197,10],[2022,147,3]]}],title:{text:\"CARLA和TORCS模拟器相关论文发表数量\",left:\"center\"},grid:{left:\"1%\",containLabel:!0},legend:{bottom:\"10%\"},tooltip:{order:\"valueDesc\",trigger:\"axis\"},xAxis:{name:\"年\",type:\"category\"},yAxis:{name:\"论文数量\",type:\"value\"},series:[{type:\"bar\"},{type:\"bar\"}]});return{Option:e}}});c(\"8d93\");const fc=o()(Oc,[[\"render\",jc],[\"__scopeId\",\"data-v-1adcce43\"]]);var lc=fc,oc=Object(b[\"j\"])({name:\"RLSection\",components:{KeywordsReinforcement:Jt,KeywordsDeepreinforcement:cc,Publication:sc,NumberPapers1:lc}});c(\"2fd8\");const dc=o()(oc,[[\"render\",qt]]);var uc=dc,hc=c(\"1b12\"),vc=c.n(hc),pc=c(\"3450\"),mc=c.n(pc),gc=c(\"f99a\"),Lc=c.n(gc),yc=c(\"4a2b\"),Sc=c.n(yc),Dc=c(\"df4a\"),Ac=c.n(Dc),Cc=c(\"4b59\"),Nc=c.n(Cc),Vc=c(\"e367\"),xc=c.n(Vc),Rc=c(\"b95b\"),kc=c.n(Rc),wc=c(\"e3f0\"),Mc=c.n(wc),Pc=c(\"1d6f\"),zc=c.n(Pc),Tc=c(\"0691\"),Ic=c.n(Tc),_c=c(\"fab5\"),Bc=c.n(_c),Gc=function(e){return Object(b[\"s\"])(\"data-v-0e0d5ebc\"),e=e(),Object(b[\"q\"])(),e},Hc=Gc((function(){return Object(b[\"f\"])(\"section\",{id:\"DL-section\",class:\"section is-medium\"},[Object(b[\"f\"])(\"h1\",{class:\"title\"},\"自动驾驶与深度学习\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"h2\",{class:\"subtitle\"},\" 针对自动驾驶的六大主要任务，即场景理解、运动规划、决策、车辆控制、社会行为和通信。\")],-1)})),Qc={id:\"深度场景理解\"},qc=Gc((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.1 场景理解\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在过去二十年中，场景理解领域使用有效的分布式语言技术取得了重大进展。这一进展使得通过使用不同的传感器（如激光雷达、摄像机和雷达）为AVS提供有关驾驶环境的关键和精确信息成为可能。事实上，深度CNN在实时图像分类和检测方面已显示出显著的结果（Fernandes et al., 2021）。如图4所示，场景理解中DL技术的使用为AVS提供了可操作的信息，如车道、交通灯、行人、交叉线、交通标志等的检测。Cordts et al. (2016)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 也就是说，感知仍然是车辆识别道路几何形状的主要先决条件之一, 并识别道路用户，如行人、自行车和其他车辆。感知分为两组：道路场景和目标检测。 \")])],-1)})),Fc=Gc((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"场景理解图片\",src:vc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：场景理解\")],-1)})),Wc=Gc((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度道路场景\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.1.1 道路场景\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 准确识别和提取主要道路信息对于AVS识别道路要素（例如路面、沟渠、护栏和栅栏）至关重要。由于DL的强大功能，可以实现高精度的道路要素识别。例如，Balado et al. (2019)使用移动激光扫描（MLS）获得的信息来识别道路环境的主要元素。他们的提议基于点网（Qi et al., 2017）和语义分割（SS）方法来识别道路元素；它为城市地区的AVS提供了良好的前景。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 识别道路的几何结构可以为AVS提供有关其环境的更多信息。Laddha et al.(2016)用基于监督和非监督学习的混合算法，使用CNN识别道路几何形状。虽然该算法减少了人为标记的工作量，并使训练更具可扩展性，但仍需要在具有关键天气条件的不同场景中对其进行评估。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 全面了解周围环境和道路区域（例如遮挡、3D几何形状和道路拓扑类型）有助于自主驾驶的实际应用。 为此，Yan et al. (2020)开发了一种基于激光雷达数据的多任务道路感知网络（LMRoadNet）方法。LMRoadNet旨在检测和估计道路测量值，如道路的长度和形状，以识别其拓扑结构。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 道路转角被认为是识别具有挑战性的区域之一。Bolte et al. (2019)的一项研究引入了道路转角的形式定义，并在AVS摄像机的视频信号中检测它们。因此，基于CNN的系统使AVS能够在关键情况下感知更好的道路。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Tümen and Ergen (2020)开发了一种图像处理方法和基于DL的方法，用于使用CNN检测公路上的十字路口、分隔带和人行横道。鉴于这些地方的事故发生率很高，这种检测对于改善道路安全至关重要。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Di et al. (2017)研究了交通场景理解问题，以从具有照明条件的图像中识别道路物体。他们考虑了基于CNN的密集对应迁移学习方法，以提取城市环境图像的深度表示。然而，这种方法没有考虑到不同和复杂的驾驶场景。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 交通标志的成功检测和分类是全自动驾驶汽车要克服的主要挑战之一。例如，Sajjad et al. (2020)开发了一种检测和避开障碍物的方法。该模型基于视觉传感器识别各种交通标志；它允许使用超声波传感器避开障碍物。作者实现了他们的原型，通过仅使用单目视觉传感器来促进车辆感知。 \")])],-1)})),Zc={class:\"content\"},Ec=Gc((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度目标检测\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.1.2 目标检测\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 准确、实时地检测周围物体，包括其他道路使用者，对于AVS来说至关重要。Wang et al. (2020b) 提出了一种基于DL技术的端到端三维目标检测方法。具体来说，他们的技术使用CNN和融合网络（FoFNet）来预测边界框和对象类别，例如汽车、行人和骑自行车的人。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Prabhakar et al. (2017)提出了一种通过考虑天气条件来提高检测效率的方法。更具体地说，他们使用区域卷积神经网络（R-CNN）来识别和分类障碍物，如车辆、行人和动物。在雨天，他们使用在每个检测到的对象顶部带有类名的边界框。然而，需要对其他道路图像数据集进行更多测试，以评估该模型的准确性和适用性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 除了目标检测之外，还需要估计其他关键参数（例如距离），以帮助实现自动驾驶。Chen et al. (2018b)提出多任务组合策略（CPMTL）算法，该算法旨在通过在检测过程中估计车辆与其他道路使用者之间的距离来改进检测。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li et al. (2021)解决了夜间使用CNN进行检测的问题，以改进微光图像识别。他们报告说，他们的提案可以帮助AVS识别道路，特别是在没有路灯的农村地区。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Dinh et al. (2020)提出了一种基于CNN的方法，用于更好地检测城市交通中的目标；他们假设AVS配备了两个焦距不同的摄像机。他们表明，他们的提议允许检测小型物体（例如，小型和遥远的车辆）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 现有的几种方法依赖视频进行目标检测；随着时间的推移，它们在连续的帧中对对象进行分类。然而，这没有考虑导致信息丢失的图像帧之间的空间和时间相关性。为了填补这一空白Liu et al.(2020) 基于运动辅助特征校准网络（MFCN）在两种情况下识别车辆，即遮挡和截断。与Ren et al. (2017), Song et al. (2018b), and Zhang et al. (2017)相比，他们的提案的评估确实表明，在不同的物体外观下，检测精度更好。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 由于来自传感器的数据量巨大，在训练过程中减少数据量可以提高检测模型的性能。基本上，只使用重要数据可以缩短基于DL的方法的训练时间。驾驶期间的时间至关重要，尤其是在紧急情况下；因此，检测必须是实时的（Das et al., 2020）。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 三维物体检测揭示了更准确的物体大小和位置信息，用于自动驾驶。自主驾驶的许多重要方面，如运动规划和车辆控制，通常需要忠实地表示车辆周围的三维空间。现有的3D物体检测贡献在使用传感器进行检测的方式上有着根本的不同。一些研究（Ma et al., 2019; Peng et al., 2020）仅使用单目摄像机。例如，Zhang et al. (2020b)提出了一种新的单目框架，用于自动驾驶场景中的三维检测；目标是使用3D盒检测和定位对象。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 其他几种方法提出了摄像机图像和激光雷达数据的融合。Chen et al. (2017a)试图通过开发基于多视图三维网络（MV3D）的三维物体检测方法来提高检测性能。他们的方案使用激光雷达点云和RGB图像来预测3D边界盒；它优于仅依赖传感器的方法。Hong et al. (2020) 提出了一种3D检测方法，该方法利用激光雷达点云和RGB图像作为交叉融合网络的输入，他们通过模拟表明，他们的提议允许检测通常仅使用传感器难以检测的对象。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 弱势道路使用者的安全仍然是一个具有挑战性的重大问题。因此，行人的检测至关重要，因为他们被视为主要的弱势道路使用者。在此背景下，Zhao et al. (2020)提出了一种称为行人位置感知网络（P-LPN）的方法；它基于内部级联网络（InCNet）。P-LPN将行人分为两组：在车道上移动的行人和在人行道上移动的行人。它使用区域建议网络（RPN）在语义地图上提供每个行人的位置。然而，P-LPN没有考虑行人的意图，这对于AVS理解行人的运动非常重要。 \")])],-1)})),Uc=Gc((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习中的场景理解方法比较\",src:mc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习中的场景理解方法\")],-1)})),Kc=Gc((function(){return Object(b[\"f\"])(\"div\",{id:\"深度运动规划\"},[Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.2 运动规划\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在场景理解（或环境感知）之后，运动规划是AVS的下一个主要任务，以避免在不同环境中发生碰撞，从而安全平稳地导航。为了处理运动规划问题，传统方法（例如：Dijkstra算法、A-Star算法、State lattice算法）依赖于优化模型。这些算法在计算范围太大时速度缓慢，不适合实时应用。因此，许多研究人员提出了替代方法，例如基于DL的技术。这些方法分析感知信息，以便识别障碍，然后预测正确的动作。这使得AVS可以通过在时间和距离方面找到有效的路径来安全导航。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 我们将运动规划分为两类：运动命令预测和轨迹预测。运动命令预测主要包括计算转向角、加速度和/或制动，而轨迹预测包括计算所有道路参与者（包括ego-vehicle）的短期轨迹及其未来状态。 \")])]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习运动规划流程\",src:Lc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：深度学习运动规划流程\")]),Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.2.1 运动命令预测\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 由于交通状况的复杂性，很难建立一个通用的运动规划系统，尤其是实时运动规划系统。事实上，道路使用者的行为仍然不可预测，难以建模。例如，Bai et al. (2018)将CNN和LSTM结合起来提取时空信息，目的是基于真实数据实时预测转向角。Song et al. (2018a)使用从驾驶模拟器收集的数据，使用类似的方法估计转向角。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen et al. (2018a)提出将CNN和LSTM结合起来进行规划决策。他们报告说，使用模拟和真实交通可以使AVS在许多情况下更好地模拟人类驾驶。然而，我们认为，应该更广泛地测试他们的方案，以评估和改进其性能。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 一些贡献（Bai et al., 2018; Song et al., 2018a; Chen et al., 2018a）只关注转向角估计；其他人确实解决了不止一个运动命令。例如，Hu et al. (2020)提出了一种基于CNN和LSTM的深度级联神经网络，以同时预测多个运动指令（即转向角、加速度和制动）。 \")])]),Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.2.2 轨迹预测\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" AVS需要分析传感器收集的数据，以检测障碍物，从而安全导航到目的地。Zhao et al. (2019)提出了卡尔曼学习网络（LKN），以根据摄像机使用DL收集的数据估计车辆轨迹。Banzhaf et al. (2019)提出了一种基于CNN的方法，该方法使用收集的数据预测车辆未来的运动，同时考虑静态障碍物和无规则的道路。因此，在他们的方案中，双向RRT*被用以减少计算时间。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Grigorescu et al. (2019)提出了一种改进AVS最优路径轨迹预测的方法。他们融合激光雷达和雷达数据来估计最佳轨迹。Cui et al. (2019)提出了一种估计其他车辆和行人轨迹的方法；他们使用CNNs处理来自激光雷达或雷达的数据。Djuric et al. (2020)使用类似的方法预测短期车辆轨迹和道路参与者（例如周围车辆）的未来状态。Deo and Trivedi (2018)提出了CNN和LSTM，以预测各种交通场景中周围车辆的未来轨迹。Zhang et al. (2020c)通过探索人类驾驶员在环境中的体验特征，使用模仿学习。它们利用CNNs处理3D环境信息，并提供周围车辆的状态。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Leordeanu and Paraicu (2021)开发了一种方法，仅基于视频和最终目的地预测AVS的当前位置和未来轨迹。该方法可以适应不同天气条件下的短期和长期导航。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Jeong et al. (2020)提出了一种基于LSTM和RNNs的运动预测算法；目标是减少十字路口的交通事故。该算法以周围车辆的状态信息为输入，预测目标状态序列。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Rehder et al. (2018)使用完全卷积网络（FCNs）操作环境地图，以推断所有可能的步行目的地。仿真结果表明，该系统能够准确预测目的地和轨迹。 \")])]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习运动规划方法\",src:Sc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习运动规划方法\")])],-1)})),Xc=Gc((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度决策\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.3 决策\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 自动驾驶的决策需要对环境进行准确而充分的描述。以往传统的方法(如启发式和数值优化)未能模拟所有可能的情况。而最近，深度学习技术已经显示出在实时和复杂环境下做出决策的能力。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li et al.(2018)利用cnn通过提取道路场景图像来模仿人类驾驶员，从而做出正确的驾驶决策。Gallardo等人(2017)在Krizhevsky et al. (2012)中提出了一种通过cnn，AlexNet架构的环境为自动驾驶汽车做决策的方法。Xie et al. (2019) 提出了一种利用LSTM对自动驾驶汽车与周围车辆之间的相互作用进行建模的变道方法 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 自动驾驶汽车的变道机动仍然是一项复杂而富有挑战性的任务。因此，发展能够考虑到周围车辆运动的精确的变道系统是必要的 。Liu et al. (2019b)提出了一种基于dnn的方法，该方法受益于驾驶员的历史经验和V2V信息，以实现准确的变道机动。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Strickland等人(2018)提出了一种在紧急情况下避免撞车的方法。为了实现这一目标，他们使用贝叶斯卷积LSTM来处理数据并避免现有的碰撞。Wang等人(2020c)使用r - cnn在环形路口引导自动驾驶汽车。他们的方案能够在自动驾驶汽车到达环形路口时做出决定(例如进入或等待)。 \")])],-1)})),Yc=Gc((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习决策算法比较\",src:Ac.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习决策算法\")],-1)})),Jc=Gc((function(){return Object(b[\"f\"])(\"div\",{id:\"深度车辆控制\",class:\"message-body\"},[Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.4 车辆控制\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 车辆控制负责纠正由运动规划和决策任务产生的错误。控制器在自动驾驶汽车中的作用是稳定和引导车辆沿着路径行驶。它接收由感知和定位模块估计的车辆状态。AVs根据这些状态选择合适的控制命令，如图6所示。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 在本节中，我们首先介绍经典的AV控制策略，这些策略允许最小化成本函数定义了一组状态和控制动作。这些传统控制器可以分为无模型和基于模型两类。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 无模型控制器:这种控制器不使用任何被控制系统的数学模型。它们允许根据设定值和当前状态之间的错误纠正操作。这些控制器很容易实现，因为它们不需要深入了解系统行为。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 然而，它们很难调优，而且不能保证最优性能，只能在有限的操作条件下良好的工作(Samak et al.， 2011)。这种控制器的一个例子是PID，它允许AVs以尽可能小的振动或抖动达到其目标状态。PID的输出依赖于三个超参数，每个超参数对应控制器缩写(P-I-D)。这些超参数特定于每个应用程序 (Kiong et al., 1999; Crenganis and Bologa, 2016)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Farag(2020)使用PID控制器控制自动驾驶汽车在路径规划器计算的轨迹上行驶。测试结果表明了PID在不同车速下的性能。 Alonso et al.(2013) 提出了一种基于二次函数最小化的PID控制器参数整定方法。他们的建议被应用于控制自动驾驶车辆跟随另一辆前面的车辆。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 基于模型的控制器:这些控制器使用数学模型来控制被控制系统。运动学控制器决定车辆的运动，忽略作用在系统上的内力或外力。特别是在加速度不显著的低速下，它们是有效的。Satouri等人(2021)使用了一个运动学模型的例子，例如自行车模型(Rajamani, 2011)，它允许控制非线性车辆的运动。该模型估计了汽车的速度和转向角，以及前、后轮胎的转向刚度。他们的方案通过CarSim模拟器进行了测试和验证，结果表明，该模型对运动规划给出的参考路径轨迹具有良好的跟踪性能。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 动态控制器考虑作用在系统上的力和力矩来估计车辆的运动。模型预测控制利用系统的线性或非线性运动模型预测其未来状态，并通过在每个时间步上求解一个优化问题来确定最优控制动作(Samak et al.， 2011)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Funke等人(2016)将模型预测和反馈控制器相结合，在保持稳定和避免碰撞的同时，估计到达预期目的地所需的转向角。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li等人(2017)提出了一种方法，允许控制自动驾驶车辆跟踪参考路径并避免碰撞(如车辆、骑自行车的人和行人)。他们的建议结合了前馈和反馈控制器(Kapania和Gerdes, 2015)来调整驾驶时的转向角度。Ni等人(2017)也使用前馈和反馈控制器来沿着期望的路径引导AV。他们的模型通过估计轮胎转向刚度来增强控制器的鲁棒性。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 以前的控制器需要深入了解过程和调优。此外，在实施合适的控制器之前，需要知道运动学或动力学模型。这些控制器只能用于特定的场景，而不适合其他情况。当场景发生变化时，它们需要重新调整。此外，他们没有考虑到每个道路使用者的行动，如其他车辆，骑自行车的人和行人。因此，在设计新的自动驾驶汽车相关方法时，考虑一般的vru，特别是行人就变得至关重要。这将有助于更好地理解和预测行人在自动驾驶汽车上路时的意图。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 值得注意的是，这些控制器不处理复杂的情况，如密集的交通，十字路口，人行横道等。它们只专注于控制自动驾驶汽车沿着运动规划产生的参考路径运动。由于这些原因，人工智能技术通过从环境中学习来获得精确的控制命令(例如，转向和调节速度)，从而超越了这些传统技术，就像我们在本小节和人工智能部分介绍的那样。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 控制系统分为两类:(a)纵向控制:调节车辆巡航速度;(b)横向控制:转向车辆车轮进行路径跟踪。 \")])]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习传统控制算法比较\",src:Nc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习传统控制算法\")]),Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度车辆横向控制\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.4.1 车辆横向控制\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 横向控制可以选择所需的转向角度，并纠正驾驶过程中可能累积的任何误差。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Rausch等人(2017)提出了一种基于cnn的转向角预测方法。他们用自动驾驶汽车摄像头收集的数据来训练他们的方案。这种方法已经在只有双车道道路没有交通的情况下进行了评估。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Sharma等人(2018)提出了一种在不同轨道(例如，多车道轨道和单车道未知轨道)上引导自动驾驶汽车的方法。他们使用cnn和TORCS (Wymann et al.， 2000)用从传感器收集的数据(即速度、转向角、油门和刹车位置)来训练和测试他们的方案。仿真结果表明，他们的模型能够成功地控制汽车，并在不越过车道标记的情况下完成整个圈速。但是，他们的方法在TORCS模拟器上只能在两条轨迹上进行仿真。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Lee和Ha(2020年)利用CNNs和LSTM来预测自动驾驶汽车的转向角。cnn用于提取驾驶过程中摄像头图像的特征。将这些特征反馈到LSTM中，进行转向角估计。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Maqueda等人(2018)解决了在不同白天时段(如白天和夜晚)估计转向角的问题。他们利用He等人(2016)使用的cnn来训练来自事件摄像机的数据(Lichtsteiner等人，2008)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Yang等人(2018b)报告称，仅预测转向角度不足以实现车辆控制。因此，他们建议估计包括速度控制的参数。他们使用带有5个卷积层和4个全连接层的cnn从Udacity模拟器(公共驾驶数据集，2017)的数据中提取特征。他们使用的训练数据集包括速度值、转向角度和三个前视摄像头的视频流。将提取的特征输入LSTM，预测舵机的转角和速度指令。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen等人(2019c)提出了使用Bojarski等人(2016)和LSTM中的cnn学习驾驶车辆的辅助任务网络(ATN)方法。他们训练他们的网络架构，根据相机的图像输入来预测转向角度。他们使用Udacity模拟器和Comma.ai dataset来评估他们的提案。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Mújica-Vargas等人(1062)研究了一种增强的司机混合驾驶方法，以在不同的情况下(例如，变道、红绿灯、交通标志和从一条路转到另一条路)引导自动驾驶汽车。他们的建议结合了cnn和rnn，其中cnn提取了从Udacity模拟器收集的数据的特征。但是，他们没有考虑到障碍物和其他道路使用者。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Kebria等人(2019)提出了一种基于cnn的架构，以减少训练时间并预测自动驾驶汽车的转向角。他们使用cnn来提取驾驶过程中记录的图像的重要特征。他们得出的结论是，在第一层拥有较大过滤器的cnn架构具有出色的性能。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Yang等人(2018a)使用TORCS (Wymann等人，2000)和CARLA (Dosovitskiy等人，2017)模拟器进行数据收集，而不是包括不同的条件(如白天和夜晚)。这些数据被输入到cnn来估计自动驾驶汽车的转向角。然而，作者没有考虑其他具有挑战性的场景(例如，十字路口和密集的交通)。 \")])]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习横向控制算法比较\",src:xc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习横向控制算法\")]),Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度车辆纵向控制\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.4.2 车辆纵向控制\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 纵向控制负责自动引导，在驾驶过程中调节自动驾驶汽车的速度，保证安全舒适。由于DL可以根据在真实世界或仿真环境中收集的标记训练数据来估计正确的速度，因此它已成为一种流行的纵向控制方法。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Mohseni等人(2018)提出了一种模型预测控制(MPC)方法来调节AVs的速度以避开障碍物。他们用从激光雷达传感器收集的数据(包括位置、大小和速度信息)来训练DNN架构。此方案的目标是在障碍物出现的地方自定义速度。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Szilassy等人(2019)提出了一种利用DNN估计路口AVs速度的控制方法。DNN以AVs的位置和初速度作为输入。然而，他们的建议没有考虑十字路口的其他关键参数(如行人行为)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" al-sharman等人(2020)提出了一种基于DNN架构的状态估计方法。他们使用真实的车辆来收集数据(车辆状态、动力系统状态和制动值)来模仿人类驾驶员。并且将数据输入DNN进行制动压力预测。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Yang等人(2018a)使用TORCS (Wymann等人，2000)和CARLA (Dosovitskiy等人，2017)模拟器进行数据收集，而不是包括不同的条件(如白天和夜晚)。这些数据被输入到cnn来估计自动驾驶汽车的转向角。然而，作者没有考虑其他具有挑战性的场景(例如，十字路口和密集的交通)。 \")])]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习横向纵向算法比较\",src:kc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习纵向控制算法\")]),Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度车辆横向纵向控制\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.4.3 车辆横纵向同时控制\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 前面的章节表明DNN可以训练为车辆的纵向或横向控制。为了改善转向和加速机制，纵向和横向控制可以同时使用。在下面的文章中，我们将简要讨论使用这两个控件的方法。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Chen等人(2015)提出了一种估计控制指令(转向、加速和制动)的方法。他们用TORCS(2021年)收集的12小时视频数据训练cnn。他们的提议使自动驾驶汽车能够在不同的场景下驾驶。Devineau等人(2018)提出了一种多层感知(MLP)方法，利用cnn训练自动驾驶汽车在具有挑战性的情况下驾驶(包括在长直线和紧密曲线之间切换)。实验结果表明，该方法对舵机转角的估计是有效的。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Sharma等人(2019年)使用TORCS(2021年)收集数据(包括按速度、转向角、油门和刹车位置标记的道路图像)。这些数据被提供给cnn，训练模型同时学习预测车辆速度和转向角度。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Xing等人(2020)开发了一种在高速公路上变道的方法。虽然该方案在训练阶段同时使用了CNNs和rnn，但尚未在车流量密集的关键情况下进行测试。 \")])]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习车辆控制算法总结\",src:Mc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习车辆控制算法总结\")]),Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习车辆控制流程\",src:zc.a,width:\"600\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"图：深度学习车辆控制流程\")])],-1)})),$c=Gc((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度学习车辆社会行为\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.5 社会行为\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 汽车行业的目标是在未来几年推出五级(全自动化)自动驾驶汽车。在未来的交通系统中获得完全的自动驾驶汽车，这都将取决于自动驾驶汽车如何识别路人的行为。DL技术在理解路人的意图，从而做出及时的交通决策方面显示出良好的结果。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 许多技术都被广泛用于理解行人在道路上的行为，无论是通过理解行人的运动还是分析行人的行为和意图。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Hoermann等人(2018)将贝叶斯滤波技术和cnn结合起来，与道路用户(包括行人、自行车和车辆)训练数据。他们的建议的目的是估计每个道路使用者的意图。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Saleh等人(2020)提出了在交通环境中理解行人意图的问题。他们仅基于来自摄像机的视频，使用黄等人(2017)的DenseNets实时检测和跟踪行人。该方法在意图预测方面取得了良好的结果。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Abughalieh和Alawneh(2020)提出了一种基于cnn和收集的图像预测行人意图的方法。他们的提案允许在人行横道上识别行人的方向和与自动驾驶汽车的距离。然而，他们没有实时考虑行人的姿势。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Morales Alvarez et al. (2020) 利用自动驾驶汽车中传感器获取的数据来识别行人的位置(例如姿势和位置)。他们利用这些信息，根据rnn估计行人过马路的意图。结果显示，75%的测试在意图预测方面是成功的。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Muscholl等人(2020)使用贝叶斯网络来理解行人过马路时的行为。结果表明，他们的建议比其他现有方法更好地估计行人位置(Gupta等人，2018年;黄等人，2019a;Mohamed等人，2020年)。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Poibrenski等人(2020年)使用rnn估计道路上每个行人的所有可能位置。对网络进行训练，根据车辆摄像头收集的图像预测行人的位置。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Elallid等人(2022)提出了一个使用P-LPN技术检测和统计避难岛上行人的模型。随着时间的推移，数字编号会被更新，并使用LSTM预测AVs的决策。这取决于等待过马路的行人数量。如果车辆数量较多，自动驾驶汽车需要刹车以给行人通过的机会，否则自动驾驶汽车会加速。 \")])],-1)})),eb=Gc((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习车辆社会行为算法比较\",src:Ic.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习车辆社会行为算法\")],-1)})),tb=Gc((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{id:\"深度学习车辆通信\",class:\"message-body\"},[Object(b[\"f\"])(\"b\",null,\"4.6 通信\"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 通信技术对提高自动驾驶车辆的感知能力和规划能力以及实现更好的车辆控制有着有效的影响。在某些情况下，传感器不能提供准确的信息。在这些情况下，通信可以用来在车辆之间共享信息。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" 信道状态信息是无线通信中的一个术语，用来描述通信链路的信道参数。这个信息代表了散射、衰落和功率随距离衰减的累积效应，描述了信号如何从发射机传播到接收机。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Du et al.(2017)提出了一种解决大面积资源分配问题的LSTM方法。他们收集了24小时的数据并进行了标记。根据历史交通数据，他们的建议可以检查一段时间内的交通量。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Li等人(2019b)提出通过共享车辆和基础设施之间的实时数据来提高V2I通信的可靠性。他们使用DNN来加速处理如此大量的数据。测试结果表明，该方法在密集流量下具有良好的性能。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Gao等人(2019)提出了一种解决V2X通信功率分配问题的方法。利用DNN实时提供资源分配解决方案。Chen等人(2019b)利用cnn来训练来自V2I和V2V通信的数据，解决了同样的问题。他们得出的结论是，与DNN架构相比，cnn降低了网络的权重，从而加快了训练过程。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Liu等人(2019a)使用LSTM训练数据(包括历史CSI)，以预测未来CSI，用于管理资源分配。他们将数据归一化，以加速网络权值的优化，并迅速找到最优解。在通道预测方面，该结果优于Xu等人(2019)的方法。 \"),Object(b[\"f\"])(\"br\"),Object(b[\"f\"])(\"br\"),Object(b[\"h\"])(\" Zhang等人(2020d)使用DNN处理GPS数据，即每辆车的时间戳、纬度和经度信息。这些数据被提供给DNN来预测CSI。 \")])],-1)})),cb=Gc((function(){return Object(b[\"f\"])(\"div\",{class:\"pic\"},[Object(b[\"f\"])(\"img\",{id:\"深度学习车辆通信算法比较\",src:Bc.a,width:\"900\",height:\"1000\"}),Object(b[\"f\"])(\"p\",null,\"表：深度学习车辆通信算法\")],-1)}));function bb(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"number-papers2\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[Hc,Object(b[\"f\"])(\"div\",Qc,[qc,Fc,Wc,Object(b[\"f\"])(\"div\",Zc,[Object(b[\"i\"])(n)]),Ec,Uc]),Kc,Xc,Yc,Jc,$c,eb,tb,cb],64)}function ab(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"d\"])(n,{id:\"number_papers2\",class:\"chart\",autoresize:!0,option:e.yardOption},null,8,[\"option\"])}var rb=Object(b[\"j\"])({name:\"NumberPapers2\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({animationDuration:5e3,dataset:[{source:[[\"年\",\"kitti\",\"flyingthings3D\",\"semantickitti\",\"nuscenes\"],[2018,230,21,51,2],[2019,369,24,9,27],[2020,456,35,57,148],[2021,524,33,83,194],[2022,325,26,68,185]]}],title:{text:\"各类自动驾驶数据集相关论文数量\",left:\"center\"},grid:{left:\"1%\",containLabel:!0},legend:{bottom:\"10%\"},tooltip:{order:\"valueDesc\",trigger:\"axis\"},xAxis:{name:\"年\",type:\"category\"},yAxis:{name:\"论文数量\",type:\"value\"},series:[{type:\"bar\"},{type:\"bar\"},{type:\"bar\"},{type:\"bar\"}]});return{yardOption:e}}});c(\"5c31\");const ib=o()(rb,[[\"render\",ab],[\"__scopeId\",\"data-v-7f259190\"]]);var nb=ib,sb=Object(b[\"j\"])({name:\"DLSection\",components:{NumberPapers2:nb}});c(\"ccf3\");const jb=o()(sb,[[\"render\",bb],[\"__scopeId\",\"data-v-0e0d5ebc\"]]);var Ob=jb,fb=function(e){return Object(b[\"s\"])(\"data-v-53a10262\"),e=e(),Object(b[\"q\"])(),e},lb=fb((function(){return Object(b[\"f\"])(\"section\",{id:\"question-section\",class:\"section is-medium\"},[Object(b[\"f\"])(\"h1\",{class:\"title\"},\"开放研究问题和未来方向\")],-1)})),ob=fb((function(){return Object(b[\"f\"])(\"article\",{class:\"message is-link\"},[Object(b[\"f\"])(\"div\",{class:\"message-body\"},\" 虽然基于深度学习和强化学习的技术在自动驾驶技术当中有着不错表现，但是在完全自动驾驶汽车上路之前，这条道路上依旧有很多困难。在本节中，我们将讨论自动驾驶技术中的深度学习和强化学习所面临的挑战、公开的研究问题以及未来的发展方向。 \")],-1)})),db={class:\"content\"},ub=Object(b[\"g\"])('<article class=\"message is-link\" data-v-53a10262><div id=\"问题场景理解\" class=\"message-body\" data-v-53a10262><b data-v-53a10262>6.1 场景理解</b><br data-v-53a10262><br data-v-53a10262> 现有的自动驾驶技术很难充分理解复杂的现实世界。到目前为止，深度学习方法在识别交通环境中的对象方面的有一定的效果。然而根据我们的分析可以看出，大多数已发表的论文并没有解决各种交通类型、天气条件和照明条件下的自动驾驶问题。 <br data-v-53a10262><br data-v-53a10262> 应该进行进一步的研究来评估其他天气条件的影响，例如雪地驾驶，每年有超过3万起车辆碰撞事故发生在多雪或结冰的道路上，或在降雪或雨夹雪期间，因此雪的威胁是真实存在的。 <br data-v-53a10262><br data-v-53a10262> 此外，仍然不能保证使用已知数据或其他数据集训练神经网络是否足以让自动驾驶汽车理解所有可能的场景。也就是说，就自动驾驶汽车将遇到的对象而言，数据集很可能是不够完整的。另外一点，目前网络上能寻找到的开源数据集绝大部分都是基于国外的数据集，国内本土实际道路环境的数据集相对较少，这对国内的自动驾驶发展也存在比较大的限制。 <br data-v-53a10262><br data-v-53a10262> 目前，视频对象检测是自动驾驶汽车的一个关键挑战，因为它是一种实时操作。我们仍然需要进一步改进视频对象检测。针对不同的检测对象，行人，车辆，车道线，以及路侧标识。每一类检测具体的都或多或少的存在一些问题。比如，在实际行车过程中，超车或转弯时，在视觉范围内只能显示车的一部分，很难对检测目标进行精确判定。2020年提出的两种方法的准确率分别达到90 %和84.6 %（Das等人2020；Liu等人2020）。接下来，我们应该通过使用更高效和更有效的运动估计和特征提取网络来提高精度。 <br data-v-53a10262><br data-v-53a10262> 复杂驾驶场景中行人位置的实时感知是自动驾驶相关研究中的另一个挑战。Zhao等人提出了一种名为P-LPN的解决方案（Zhao等人，2020），用于对在车道上移动或站在人行道上的行人进行分类。然而，这种方法仍然不足以让自动驾驶汽车理解行人的运动。如何将各类行人意图预测整合到模型中仍然是进一步工作的重中之重。 <br data-v-53a10262><br data-v-53a10262> 对于对象检测和分类，深度学习的缺点之一是需要庞大的数据集。模型需要用各种各样的数据来训练，以消除任何可能的偏差。与人类的反应相比，自动驾驶汽车可以对相同的情况做出完全不同的反应，这可能造成危险。深度学习方法总是使用相同的优化算法来调整神经网络的权重。因此，它们需要先进的优化技术来获得可接受的结果。 <br data-v-53a10262><br data-v-53a10262> 自动驾驶汽车检测路上的行人以识别他们的意图。基于意图预测，自动驾驶汽车决定如何避开行人。然而，行人的动作是不可预测的，有时很难估计他们的意图。自动驾驶汽车如何在困难情况下检测识别行人行为？还有很多情况可能会导致意想不到的结果。比如当积雪隐藏交通信号灯时，自动驾驶汽车如何应对？ </div></article><article class=\"message is-link\" data-v-53a10262><div id=\"问题运动规划\" class=\"message-body\" data-v-53a10262><b data-v-53a10262>6.2 运动规划</b><br data-v-53a10262><br data-v-53a10262> 在驾驶过程中，自动驾驶汽车面对复杂的城市交通，尤其是位于繁华市中心的十字路口或者处于拥堵时段时，怎么才能平稳安全的导航？我们发现只有少数研究成果在现实世界中付诸实践，而其他绝大多数是基于模拟环境的。在模拟环境中的实现与现实部署之间存在不可逾越的鸿沟。此外，目前的成果仅在特定的驾驶条件下进行评估，尚未在其他复杂的场景下进行验证。 <br data-v-53a10262><br data-v-53a10262> 虽然很多仿真平台都具有传感器建模仿真、车辆动力学建模仿真以及交通场景建模仿真的能力，但仿真模型大多都是建立在理想条件的情况下，仿真模拟器模拟出来的结果的置信度到底怎么样，还没有具体可量化的指标去评价。 <br data-v-53a10262><br data-v-53a10262> 此外，由于不同国家和地区的车辆行驶环境的差异化，导致测试场景数据的具有很强的地域属性。测试车辆面对的极端工况场景在数量和内容形式上也会有很大的不同。 <br data-v-53a10262><br data-v-53a10262> 部分现有方法使用SUMO来模拟强化学习模型。然而，SUMO仅限于2D模拟，这使得它不适合用于真实世界。此外，大多数现有方法使用旧版本的模拟器，例如Udacity和CARLA。因此，未来的方法应该在提供新特性的最新版本中进行测试。例如，最新版本的CARLA 0.9.13允许将行人（包括成人和儿童）纳入具有3D位置的模拟中。这些新功能可以帮助研究人员使用更复杂的场景进行实验。 <br data-v-53a10262><br data-v-53a10262> 大多数现有方法使用几种模拟器来评估自动驾驶汽车，以了解它们如何在不同场景中实现安全导航（例如Udacity、TORCS和CARLA）。然而，这些方法需要在现实生活场景中进行测试，以检查它们是否能在现实世界中保持其性能。 <br data-v-53a10262><br data-v-53a10262> 当前的自动驾驶仿真软件确实很多。VTD、Prescan、51Simone、PanoSim、GaiA、rfPro、CARLA、Airsim、Lgsvl、DeepDrive、Carsim、CarMaker；甚至Matlab/Simulink、GTA-5、Gazebo都可用于自动驾驶仿真。每个仿真软件都有自己的优缺点，如果面对具体测试需求不断切换要使用的模拟器，无疑会增加很多学习成本。 <br data-v-53a10262><br data-v-53a10262> 目前很难说有一款公认的足够完美的自动驾驶仿真软件。大部分软件都还不能同时支持以下列举的全部功能： <br data-v-53a10262><br data-v-53a10262> • 由于可能破坏物理引擎的稳定性无法提供高于实时的模拟速度； <br data-v-53a10262><br data-v-53a10262> • 不支持高效的无GUI运行(headless execution)模式进而影响自动化测试等； <br data-v-53a10262><br data-v-53a10262> • 建模基于复杂多维真实交通行为的动态场景时需要较高数据成本以及专业知识； <br data-v-53a10262><br data-v-53a10262> • 构建大规模真实、异构静态场景时需要较高时间成本； <br data-v-53a10262><br data-v-53a10262> • 适配多种场景语言（或者说，将场景编码为场景语言）时，需要较高的时间成本； <br data-v-53a10262><br data-v-53a10262> • 不支持多agent联合仿真以及跨多台机器仿真会话有效分发； <br data-v-53a10262><br data-v-53a10262> • 不支持大规模场景 </div></article><article class=\"message is-link\" data-v-53a10262><div id=\"问题决策\" class=\"message-body\" data-v-53a10262><b data-v-53a10262>6.3 决策</b><br data-v-53a10262><br data-v-53a10262> 自动驾驶决策的核心就是要解决车辆该怎么走的问题。一辆自动驾驶车辆处在周围有行人、自行车以及前方有卡车驶来的环境下，现在它需要左转，该怎么做？这就是该解决的问题。 <br data-v-53a10262><br data-v-53a10262> 交通状况较为拥堵时，由于道路使用者（其他汽车、自行车和行人）的高度流动性，自动驾驶汽车总是很难做出正确的驾驶决策。深度学习和强化学习的研究显示，这个问题是有希望基于这些技术解决的。然而，面对真实的更复杂的情况（如交叉路口和人行横道）仍需要进一步研究。 <br data-v-53a10262><br data-v-53a10262> 无人车的行为决策模块是一个信息汇聚的地方。由于需要考虑如此多种不同类型的信息以及受到非常本地化的交规限制，行为决策问题往往很难用一个单纯的数学模型来进解决。往往更适合行为决策模块的解决方法，是利用一些软件工程的先进观念来设计一些规则引擎系统。 <br data-v-53a10262><br data-v-53a10262> 目前的决策方法往往是使用监督学习技术去模仿人类驾驶。但很显然，这种方法并不能涵盖所有可能的驾驶场景，并且很难为每个国家的不同驾驶场景收集所有必要的数据。 <br data-v-53a10262><br data-v-53a10262> 此外，还有必须解决的两个主要目标，即方法的鲁棒性和灵活性，这使得自动驾驶汽车能够在没有先验知识情况下处理未知情况。 <br data-v-53a10262><br data-v-53a10262> 有许多意想不到的事件需要研究人员的进一步研究。例如，自动驾驶汽车可能会因为道路上不存在碰撞风险而决定加速。然而，行人可能同时突然穿越马路。这让我们不禁要问自动驾驶汽车如何避开这个行人？深度学习和强化学习如何处理这样的情况？ <br data-v-53a10262><br data-v-53a10262> 现有方法部署深度学习和强化学习技术来训练自动驾驶汽车从环境（例如高速公路、交通和十字路口）中学习。然而，我们发现了三个主要的问题亟待解决： <br data-v-53a10262><br data-v-53a10262> (1) 大多数方法没有考虑到其他道路使用者（如行人和骑自行车的人）； <br data-v-53a10262><br data-v-53a10262> (2) 几乎所有方法都没有处理不同的天气和照明条件（例如雪和夜晚）； <br data-v-53a10262><br data-v-53a10262> (3) 自动驾驶汽车被训练从模拟环境中学习，但是它们应该在真实世界中接受测试，以确认它们的能力； </div></article><article class=\"message is-link\" data-v-53a10262><div id=\"问题车辆控制\" class=\"message-body\" data-v-53a10262><b data-v-53a10262>6.4 车辆控制</b><br data-v-53a10262><br data-v-53a10262> 自动驾驶汽车控制技术的作用是纠正由运动规划和决策任务所产生的任何错误。目前，建立实时校正误差的控制系统仍然是一个挑战。当给出了所有道路使用者的运动规划，自动驾驶汽车应该如何控制速度以避免事故。 <br data-v-53a10262><br data-v-53a10262> 车辆控制系统的主要挑战是开发出能够应对不同环境的方法。例如，在城市交通中成功的控制策略可能不适用于具有不同交通特性和安全问题的高速公路。 <br data-v-53a10262><br data-v-53a10262> 在良好的天气条件下对几种方法进行测试并不足以实现自动驾驶的安全性。比如，在晴天控制速度或者刹车，与在下雪天就不一样。因此，有必要涵盖所有潜在的条件，以验证自动驾驶方法的效率。 <br data-v-53a10262><br data-v-53a10262> 强化学习的主要目标是奖励回报最大化。大多数现有方法使用大量的负面奖励来避免不必要的行为。然而，武断的使用这些负面奖励并不能有效地应对道路上的最终碰撞。因此，有必要使用基于周围车辆、自我车辆和其他参数的速度和位置的数学方程来选择奖励。例如，Knox等人（2021）研究了自动驾驶中的奖励设计问题，并提出了一些方案来帮助研究人员构建奖励。 </div></article><article class=\"message is-link\" data-v-53a10262><div id=\"问题车辆社会行为\" class=\"message-body\" data-v-53a10262><b data-v-53a10262>6.5 车辆社会行为</b><br data-v-53a10262><br data-v-53a10262> 自动驾驶技术中最困难的任务是理解其他道路使用者的意图。例如，行人是最容易受到伤害的道路使用者，而自动驾驶车辆想要理解行人的行为无疑是非常困难的。因此，在行使期间实时预测行人的未来位置对于自动驾驶系统来说仍然是一个挑战。 <br data-v-53a10262><br data-v-53a10262> 当自动驾驶汽车检测到行人时，自动驾驶方法不仅要检测出行人，还应理解行人的运动和意图。例如，行人在过马路时是否注意力集中、行人通过的速度是否相近、能否识别是儿童、成人还是老人等不同过马路方式的人群。 <br data-v-53a10262><br data-v-53a10262> 深度学习和强化学习显示了它们识别物体并在环境中避开它们的优良性能。不过，我们要开发更加行之有效的方法，实时估计行人或其他道路参与者的意图，还需要做更多的工作。 <br data-v-53a10262><br data-v-53a10262> 大多数研究人员只保护行人，而忽略了其他道路使用者（如摩托车和骑自行车的人），而统计数据显示，其他的道路参与者也有很多死于交通事故。 <br data-v-53a10262><br data-v-53a10262> 还有一个问题是，自动驾驶汽车应该如何与人类驾驶员交互？这个问题不容被忽视，因为在可预见的未来，人类驾驶员始终会出现在道路上。 </div></article><article class=\"message is-link\" data-v-53a10262><div id=\"问题车辆通信\" class=\"message-body\" data-v-53a10262><b data-v-53a10262>6.6 车辆通信</b><br data-v-53a10262><br data-v-53a10262> 通信是十分必要的，它能弥补传感器的局限性，进而更多地了解道路参与者的运动。该领域的主要挑战是如何利用深度学习或强化学习来实时处理来自V2V和V2I的大数据流，并在几秒钟内做出决策。 <br data-v-53a10262><br data-v-53a10262> 人类驾驶员可以使用手势（或眼神交流）与行人交流，这在自动驾驶汽车中是不可能的。在未来解决这个问题是十分重要的，这可以增强人类对自动驾驶汽车的信心。 <br data-v-53a10262><br data-v-53a10262> V2V技术允许车辆通过转发自身及前方的实时信息来预防事故的发生，从而减少驾驶时间，最终实现改善交通环境，减少交通拥堵的目的。但是，V2V通信仍然不能保证自动驾驶汽车之间信息传输的可靠。部分自动驾驶汽车可能会错过共享的消息。因此，问题是如何构建可靠的自动驾驶汽车，使得它即使在缺少共享道路信息的情况下也能安全驾驶。 <br data-v-53a10262><br data-v-53a10262> V2I技术通过无线的方式帮助车辆和路侧的交通设施实现数据交换，主要应用包括交叉路口安全管理、车辆限速控制、电子收费、运输安全管理，以及道路施工和限高警示等。这项技术会推动交通设施智能化，包括禁止驶入灯标、天气信息系统等交通设施都可进化为通过多种算法可识别高风险情况并自动采取警示措施的智能交通设施。 <br data-v-53a10262><br data-v-53a10262> 距离开发出一个理想的基于深度学习的协作式自动驾驶框架，我们还有很多的工作要做。这样的技术可以帮助自动驾驶汽车有效地提高学习精度，并降低环境感知和内容共享的成本。 </div></article>',6);function hb(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"highest-driving-score\"),s=Object(b[\"v\"])(\"highest-route-completion\");return Object(b[\"p\"])(),Object(b[\"e\"])(b[\"a\"],null,[lb,ob,Object(b[\"f\"])(\"div\",db,[Object(b[\"i\"])(n),Object(b[\"i\"])(s)]),ub],64)}function vb(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"d\"])(n,{id:\"chart-highest-driving-score\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])}var pb=Object(b[\"j\"])({name:\"HighestDrivingScore\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"Carla模拟器中各时间段最高驾驶得分方法排行\",left:\"center\"},tooltip:{formatter:function(e){var t=e.value;return'<div style=\"border-bottom: 1px solid rgba(255,255,255,.3); font-size: 16px;padding-bottom: 7px;margin-bottom: 7px;\"> '+t[2]+\"(\"+t[1]+\")</div>\"}},xAxis:{type:\"time\",name:\"时间轴\",min:\"2020-09-01\",max:\"2022-08-01\"},yAxis:{type:\"value\",name:\"驾驶分数\"},series:[{name:\"\",data:[[\"2020-10-01\",8.94,\"LBC\"],[\"2020-12-01\",24.98,\"MaRLn\"],[\"2021-04-01\",31.37,\"World on Rails\"],[\"2021-08-01\",36.79,\"GRIAD\"],[\"2022-04-01\",61.84,\"LAV\"],[\"2022-05-01\",75.14,\"TCP\"],[\"2022-07-01\",76.18,\"InterFuser\"]],type:\"line\",symbolSize:10}]});return{option:e}}});c(\"b23d\");const mb=o()(pb,[[\"render\",vb],[\"__scopeId\",\"data-v-024e0e01\"]]);var gb=mb;function Lb(e,t,c,a,r,i){var n=Object(b[\"v\"])(\"v-chart\");return Object(b[\"p\"])(),Object(b[\"d\"])(n,{id:\"chart-highest-route-completion\",class:\"chart\",autoresize:!0,option:e.option},null,8,[\"option\"])}var yb=Object(b[\"j\"])({name:\"HighestRouteCompletion\",components:{VChart:A[\"b\"]},setup:function(){var e=Object(b[\"t\"])({title:{text:\"Carla模拟器中各时间段最远行驶距离方法排行\",left:\"center\"},tooltip:{formatter:function(e){var t=e.value;return'<div style=\"border-bottom: 1px solid rgba(255,255,255,.3); font-size: 16px;padding-bottom: 7px;margin-bottom: 7px;\"> '+t[2]+\"(\"+t[1]+\")</div>\"}},xAxis:{type:\"time\",name:\"时间轴\",min:\"2020-09-01\",max:\"2022-08-01\"},yAxis:{type:\"value\",name:\"行驶里程\"},series:[{name:\"\",data:[[\"2020-10-01\",17.54,\"LBC\"],[\"2020-12-01\",46.97,\"MaRLn\"],[\"2021-04-01\",57.65,\"World on Rails\"],[\"2021-08-01\",61.85,\"GRIAD\"],[\"2021-09-01\",69.84,\"Transfuser\"],[\"2022-04-01\",94.459,\"LAV\"]],type:\"line\",symbolSize:10}]});return{option:e}}});c(\"de8c\");const Sb=o()(yb,[[\"render\",Lb],[\"__scopeId\",\"data-v-c1a7044c\"]]);var Db=Sb,Ab=Object(b[\"j\"])({name:\"TradeSection\",components:{HighestDrivingScore:gb,HighestRouteCompletion:Db}});c(\"4c72\");const Cb=o()(Ab,[[\"render\",hb],[\"__scopeId\",\"data-v-53a10262\"]]);var Nb=Cb,Vb={name:\"App\",components:{SensorSection:st,TradeSection:Me,ForewordSection:ce,Header:u,Footer:y,Sections:V,TableOfContents:T,Begining:He,End:ut,RLSection:uc,DLSection:Ob,QuestionSection:Nb}};c(\"2e78\");const xb=o()(Vb,[[\"render\",i]]);var Rb=xb;c(\"87a1\"),c(\"b383\"),c(\"77ed\");Object(b[\"c\"])(Rb).mount(\"#app\")},\"59b0\":function(e,t,c){\"use strict\";c(\"1ac8\")},\"5b8a\":function(e,t,c){e.exports=c.p+\"img/zdjsqcsdcgq.bde9027e.png\"},\"5c31\":function(e,t,c){\"use strict\";c(\"c739\")},\"5ed8\":function(e,t,c){e.exports=c.p+\"img/zdjszdldrw.397748de.png\"},\"5f28\":function(e,t,c){e.exports=c.p+\"img/2D.87fac2f2.png\"},\"645d\":function(e,t,c){},6594:function(e,t,c){\"use strict\";c(\"9c3f\")},6644:function(e,t,c){e.exports=c.p+\"img/rlsflct.bda83009.png\"},\"6afc\":function(e,t,c){\"use strict\";c(\"b11c\")},\"892b\":function(e,t,c){},\"8d93\":function(e,t,c){\"use strict\";c(\"ad49\")},\"8e88\":function(e,t,c){},\"9c3f\":function(e,t,c){},\"9d82\":function(e,t,c){\"use strict\";c(\"ed17\")},\"9e06\":function(e,t,c){\"use strict\";c(\"892b\")},\"9e80\":function(e,t,c){},a462:function(e,t,c){\"use strict\";c(\"56d7\")},ad49:function(e,t,c){},b11c:function(e,t,c){},b23d:function(e,t,c){\"use strict\";c(\"0928\")},b383:function(e,t,c){},b69b:function(e,t,c){\"use strict\";c(\"cc06\")},b8d2:function(e,t,c){\"use strict\";c(\"c55b\")},b95b:function(e,t,c){e.exports=c.p+\"img/dlzxkzsfbj.d0538c4c.png\"},be4c:function(e,t,c){\"use strict\";c(\"30cd\")},c282:function(e,t,c){e.exports=c.p+\"img/gbzdjsdjfj.9eef8f12.png\"},c55b:function(e,t,c){},c739:function(e,t,c){},c8de:function(e,t,c){e.exports=c.p+\"img/rljclc.b4fa0c61.png\"},cc06:function(e,t,c){},cc32:function(e,t,c){e.exports=c.p+\"img/rlydghff.84bd6d93.png\"},ccf3:function(e,t,c){\"use strict\";c(\"ce63\")},ce63:function(e,t,c){},d54d:function(e,t,c){\"use strict\";c(\"f9c5\")},de8c:function(e,t,c){\"use strict\";c(\"fdc4\")},df4a:function(e,t,c){e.exports=c.p+\"img/dljcsfbj.2b3e8c85.png\"},dfb9:function(e,t,c){e.exports=c.p+\"img/zdjsyzsjjfa.9395edd5.png\"},e0c3:function(e,t,c){},e2c5:function(e,t,c){},e367:function(e,t,c){e.exports=c.p+\"img/dlhxkzsfbj.0577d878.png\"},e3f0:function(e,t,c){e.exports=c.p+\"img/dlclkzsfdb.b52b09c2.png\"},eb63:function(e,t,c){e.exports=c.p+\"img/rlclkzlc.2ac9edce.png\"},ed17:function(e,t,c){},f99a:function(e,t,c){e.exports=c.p+\"img/dlydghlc.5a8daa19.png\"},f9c5:function(e,t,c){},fa85:function(e,t,c){},fab5:function(e,t,c){e.exports=c.p+\"img/dlcltxsfbj.b20fe657.png\"},fd84:function(e,t,c){\"use strict\";c(\"fa85\")},fdc4:function(e,t,c){}});","extractedComments":[]}